{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ar-yukoh.shimizu/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import os\n",
    "import chess.pgn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_values = {\n",
    "    \"p\": 1,\n",
    "    \"n\": 3,\n",
    "    \"b\": 3,\n",
    "    \"r\": 5,\n",
    "    \"q\": 9,\n",
    "    \"k\": 1000,\n",
    "    \"P\": -1,\n",
    "    \"N\": -3,\n",
    "    \"B\": -3,\n",
    "    \"R\": -5,\n",
    "    \"Q\": -9,\n",
    "    \"K\": -1000,\n",
    "}\n",
    "\n",
    "def createStateObj(board):\n",
    "    # convert state into a 8x8x12 tensor\n",
    "    state = np.zeros(774) # 8 * 8 * 12 + 5\n",
    "    net_piece_value = 0\n",
    "\n",
    "    for square, piece in board.piece_map().items():\n",
    "        for square, piece in board.piece_map().items():\n",
    "            net_piece_value += piece_values[str(piece)]\n",
    "            if piece.color == chess.WHITE:\n",
    "                state[square * 12 + piece.piece_type - 1] = 1\n",
    "            else:\n",
    "                state[square * 12 + piece.piece_type + 5] = 1\n",
    "\n",
    "    # flatten state\n",
    "    state = state.flatten()\n",
    "\n",
    "    # append the 5 states above\n",
    "    p1_can_castle_queenside = board.has_queenside_castling_rights(chess.WHITE)\n",
    "    p1_can_castle_kingside = board.has_kingside_castling_rights(chess.WHITE)\n",
    "    p2_can_castle_queenside = board.has_queenside_castling_rights(chess.BLACK)\n",
    "    p2_can_castle_kingside = board.has_kingside_castling_rights(chess.BLACK)\n",
    "    turn = board.turn\n",
    "\n",
    "    state[768] = p1_can_castle_queenside\n",
    "    state[769] = p1_can_castle_kingside\n",
    "    state[770] = p2_can_castle_queenside\n",
    "    state[771] = p2_can_castle_kingside\n",
    "    state[772] = net_piece_value\n",
    "    state[773] = float(turn)\n",
    "    \n",
    "    return state\n",
    "\n",
    "\n",
    "start = 0\n",
    "flag = 0\n",
    "\n",
    "def createData(start, n_data=10000):\n",
    "    with open(\"DATABASE4U_CLEANED.pgn\", \"r\") as rf:\n",
    "        for i in range(start):\n",
    "            game = chess.pgn.read_game(rf)\n",
    "\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        for i in range(start, start + n_data):\n",
    "            game = chess.pgn.read_game(rf)\n",
    "            if game is None:\n",
    "                flag = 1\n",
    "                break\n",
    "\n",
    "            if game.headers[\"Result\"] == '1/2-1/2':\n",
    "                win = 0\n",
    "            elif game.headers[\"Result\"] == '1-0':\n",
    "                win = 1\n",
    "            elif game.headers[\"Result\"] == '0-1':\n",
    "                win = -1\n",
    "            else:\n",
    "                print(\"Error: Unexpected result string\" + game.headers[\"Result\"])\n",
    "                continue\n",
    "\n",
    "            board = game.board()\n",
    "\n",
    "            lst = list(game.mainline_moves())\n",
    "            l_lst = len(lst)\n",
    "            r1, r2 = random.randint(0, l_lst), random.randint(0, l_lst)\n",
    "            r1, r2 = min(r1, r2), max(r1, r2)\n",
    "\n",
    "            for i in range(r1):\n",
    "                board.push(lst[i])\n",
    "            X.append(createStateObj(board))\n",
    "            y.append(win)\n",
    "\n",
    "            if r1 == r2:\n",
    "                continue\n",
    "\n",
    "            for i in range(r1, r2):\n",
    "                board.push(lst[i])\n",
    "            X.append(createStateObj(board))\n",
    "            y.append(win)\n",
    "    \n",
    "    data = list(zip(X, y))\n",
    "    random.shuffle(data)\n",
    "    X, y = zip(*data)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(774, 128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr = 0.0001\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, start=0):\n",
    "        self.start = start\n",
    "\n",
    "    def _create_data(self, step):\n",
    "        if os.path.exists(f\"data/{self.start}_{self.start+step}X.npy\") and os.path.exists(\n",
    "            f\"data/{self.start}_{self.start+step}y.npy\"\n",
    "        ):\n",
    "            X = np.load(f\"data/{self.start}_{self.start+step}X.npy\")\n",
    "            y = np.load(f\"data/{self.start}_{self.start+step}y.npy\")\n",
    "\n",
    "        else:\n",
    "            X, y = createData(self.start, step)\n",
    "            np.save(f\"data/{self.start}_{self.start+step}X.npy\", X)\n",
    "            np.save(f\"data/{self.start}_{self.start+step}y.npy\", y)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def get_data(self, step=10000):\n",
    "        X, y = self._create_data(step)\n",
    "        self.start += step\n",
    "\n",
    "        return list(zip(X, y))\n",
    "\n",
    "\n",
    "trainLoader = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unexpected result string*\n",
      "[1,   100] loss: 0.913\n",
      "[1,   200] loss: 0.900\n",
      "[1,   300] loss: 0.938\n",
      "[1,   400] loss: 0.871\n",
      "[1,   500] loss: 0.867\n",
      "[1,   600] loss: 0.821\n",
      "[1,   700] loss: 0.860\n",
      "[1,   800] loss: 0.889\n",
      "[1,   900] loss: 0.905\n",
      "[1,  1000] loss: 0.863\n",
      "[1,  1100] loss: 0.831\n",
      "[1,  1200] loss: 0.871\n",
      "[1,  1300] loss: 0.950\n",
      "[1,  1400] loss: 0.856\n",
      "[1,  1500] loss: 0.813\n",
      "[1,  1600] loss: 0.851\n",
      "[1,  1700] loss: 0.873\n",
      "[1,  1800] loss: 0.850\n",
      "[1,  1900] loss: 0.881\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "[2,   100] loss: 0.814\n",
      "[2,   200] loss: 0.826\n",
      "[2,   300] loss: 0.854\n",
      "[2,   400] loss: 0.840\n",
      "[2,   500] loss: 0.831\n",
      "[2,   600] loss: 0.836\n",
      "[2,   700] loss: 0.847\n",
      "[2,   800] loss: 0.799\n",
      "[2,   900] loss: 0.791\n",
      "[2,  1000] loss: 0.817\n",
      "[2,  1100] loss: 0.833\n",
      "[2,  1200] loss: 0.793\n",
      "[2,  1300] loss: 0.824\n",
      "[2,  1400] loss: 0.857\n",
      "[2,  1500] loss: 0.769\n",
      "[2,  1600] loss: 0.848\n",
      "[2,  1700] loss: 0.798\n",
      "[2,  1800] loss: 0.771\n",
      "[2,  1900] loss: 0.838\n",
      "[3,   100] loss: 0.890\n",
      "[3,   200] loss: 0.896\n",
      "[3,   300] loss: 0.830\n",
      "[3,   400] loss: 0.834\n",
      "[3,   500] loss: 0.841\n",
      "[3,   600] loss: 0.859\n",
      "[3,   700] loss: 0.771\n",
      "[3,   800] loss: 0.881\n",
      "[3,   900] loss: 0.827\n",
      "[3,  1000] loss: 0.850\n",
      "[3,  1100] loss: 0.854\n",
      "[3,  1200] loss: 0.869\n",
      "[3,  1300] loss: 0.861\n",
      "[3,  1400] loss: 0.897\n",
      "[3,  1500] loss: 0.874\n",
      "[3,  1600] loss: 0.851\n",
      "[3,  1700] loss: 0.857\n",
      "[3,  1800] loss: 0.788\n",
      "[3,  1900] loss: 0.837\n",
      "Error: Unexpected result string*\n",
      "[4,   100] loss: 0.814\n",
      "[4,   200] loss: 0.672\n",
      "[4,   300] loss: 0.751\n",
      "[4,   400] loss: 0.784\n",
      "[4,   500] loss: 0.839\n",
      "[4,   600] loss: 0.839\n",
      "[4,   700] loss: 0.844\n",
      "[4,   800] loss: 0.777\n",
      "[4,   900] loss: 0.767\n",
      "[4,  1000] loss: 0.720\n",
      "[4,  1100] loss: 0.859\n",
      "[4,  1200] loss: 0.814\n",
      "[4,  1300] loss: 0.715\n",
      "[4,  1400] loss: 0.773\n",
      "[4,  1500] loss: 0.848\n",
      "[4,  1600] loss: 0.856\n",
      "[4,  1700] loss: 0.769\n",
      "[4,  1800] loss: 0.749\n",
      "[4,  1900] loss: 0.699\n",
      "Error: Unexpected result string*\n",
      "[5,   100] loss: 0.798\n",
      "[5,   200] loss: 0.848\n",
      "[5,   300] loss: 0.801\n",
      "[5,   400] loss: 0.836\n",
      "[5,   500] loss: 0.804\n",
      "[5,   600] loss: 0.754\n",
      "[5,   700] loss: 0.719\n",
      "[5,   800] loss: 0.760\n",
      "[5,   900] loss: 0.856\n",
      "[5,  1000] loss: 0.792\n",
      "[5,  1100] loss: 0.798\n",
      "[5,  1200] loss: 0.725\n",
      "[5,  1300] loss: 0.826\n",
      "[5,  1400] loss: 0.794\n",
      "[5,  1500] loss: 0.778\n",
      "[5,  1600] loss: 0.817\n",
      "[5,  1700] loss: 0.725\n",
      "[5,  1800] loss: 0.767\n",
      "[5,  1900] loss: 0.771\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "[6,   100] loss: 0.844\n",
      "[6,   200] loss: 0.791\n",
      "[6,   300] loss: 0.800\n",
      "[6,   400] loss: 0.696\n",
      "[6,   500] loss: 0.840\n",
      "[6,   600] loss: 0.875\n",
      "[6,   700] loss: 0.927\n",
      "[6,   800] loss: 0.830\n",
      "[6,   900] loss: 0.774\n",
      "[6,  1000] loss: 0.818\n",
      "[6,  1100] loss: 0.866\n",
      "[6,  1200] loss: 0.806\n",
      "[6,  1300] loss: 0.704\n",
      "[6,  1400] loss: 0.827\n",
      "[6,  1500] loss: 0.846\n",
      "[6,  1600] loss: 0.891\n",
      "[6,  1700] loss: 0.810\n",
      "[6,  1800] loss: 0.715\n",
      "[6,  1900] loss: 0.914\n",
      "[7,   100] loss: 0.693\n",
      "[7,   200] loss: 0.745\n",
      "[7,   300] loss: 0.716\n",
      "[7,   400] loss: 0.743\n",
      "[7,   500] loss: 0.650\n",
      "[7,   600] loss: 0.765\n",
      "[7,   700] loss: 0.864\n",
      "[7,   800] loss: 0.781\n",
      "[7,   900] loss: 0.743\n",
      "[7,  1000] loss: 0.753\n",
      "[7,  1100] loss: 0.723\n",
      "[7,  1200] loss: 0.778\n",
      "[7,  1300] loss: 0.764\n",
      "[7,  1400] loss: 0.735\n",
      "[7,  1500] loss: 0.690\n",
      "[7,  1600] loss: 0.701\n",
      "[7,  1700] loss: 0.692\n",
      "[7,  1800] loss: 0.772\n",
      "[7,  1900] loss: 0.773\n",
      "[8,   100] loss: 0.703\n",
      "[8,   200] loss: 0.729\n",
      "[8,   300] loss: 0.845\n",
      "[8,   400] loss: 0.698\n",
      "[8,   500] loss: 0.831\n",
      "[8,   600] loss: 0.771\n",
      "[8,   700] loss: 0.807\n",
      "[8,   800] loss: 0.637\n",
      "[8,   900] loss: 0.805\n",
      "[8,  1000] loss: 0.774\n",
      "[8,  1100] loss: 0.716\n",
      "[8,  1200] loss: 0.757\n",
      "[8,  1300] loss: 0.668\n",
      "[8,  1400] loss: 0.622\n",
      "[8,  1500] loss: 0.671\n",
      "[8,  1600] loss: 0.681\n",
      "[8,  1700] loss: 0.599\n",
      "[8,  1800] loss: 0.711\n",
      "[8,  1900] loss: 0.716\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "[9,   100] loss: 0.675\n",
      "[9,   200] loss: 0.687\n",
      "[9,   300] loss: 0.607\n",
      "[9,   400] loss: 0.732\n",
      "[9,   500] loss: 0.553\n",
      "[9,   600] loss: 0.667\n",
      "[9,   700] loss: 0.730\n",
      "[9,   800] loss: 0.718\n",
      "[9,   900] loss: 0.626\n",
      "[9,  1000] loss: 0.676\n",
      "[9,  1100] loss: 0.751\n",
      "[9,  1200] loss: 0.642\n",
      "[9,  1300] loss: 0.618\n",
      "[9,  1400] loss: 0.787\n",
      "[9,  1500] loss: 0.669\n",
      "[9,  1600] loss: 0.687\n",
      "[9,  1700] loss: 0.601\n",
      "[9,  1800] loss: 0.641\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "[10,   100] loss: 0.751\n",
      "[10,   200] loss: 0.596\n",
      "[10,   300] loss: 0.691\n",
      "[10,   400] loss: 0.654\n",
      "[10,   500] loss: 0.628\n",
      "[10,   600] loss: 0.559\n",
      "[10,   700] loss: 0.654\n",
      "[10,   800] loss: 0.626\n",
      "[10,   900] loss: 0.558\n",
      "[10,  1000] loss: 0.594\n",
      "[10,  1100] loss: 0.527\n",
      "[10,  1200] loss: 0.562\n",
      "[10,  1300] loss: 0.591\n",
      "[10,  1400] loss: 0.631\n",
      "[10,  1500] loss: 0.547\n",
      "[10,  1600] loss: 0.671\n",
      "[10,  1700] loss: 0.651\n",
      "[10,  1800] loss: 0.550\n",
      "[10,  1900] loss: 0.633\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "[11,   100] loss: 0.691\n",
      "[11,   200] loss: 0.613\n",
      "[11,   300] loss: 0.599\n",
      "[11,   400] loss: 0.732\n",
      "[11,   500] loss: 0.693\n",
      "[11,   600] loss: 0.677\n",
      "[11,   700] loss: 0.737\n",
      "[11,   800] loss: 0.706\n",
      "[11,   900] loss: 0.747\n",
      "[11,  1000] loss: 0.714\n",
      "[11,  1100] loss: 0.662\n",
      "[11,  1200] loss: 0.576\n",
      "[11,  1300] loss: 0.754\n",
      "[11,  1400] loss: 0.749\n",
      "[11,  1500] loss: 0.759\n",
      "[11,  1600] loss: 0.797\n",
      "[11,  1700] loss: 0.743\n",
      "[11,  1800] loss: 0.691\n",
      "[11,  1900] loss: 0.654\n",
      "Error: Unexpected result string*\n",
      "[12,   100] loss: 0.710\n",
      "[12,   200] loss: 0.783\n",
      "[12,   300] loss: 0.759\n",
      "[12,   400] loss: 0.580\n",
      "[12,   500] loss: 0.629\n",
      "[12,   600] loss: 0.639\n",
      "[12,   700] loss: 0.631\n",
      "[12,   800] loss: 0.661\n",
      "[12,   900] loss: 0.685\n",
      "[12,  1000] loss: 0.671\n",
      "[12,  1100] loss: 0.669\n",
      "[12,  1200] loss: 0.701\n",
      "[12,  1300] loss: 0.699\n",
      "[12,  1400] loss: 0.767\n",
      "[12,  1500] loss: 0.678\n",
      "[12,  1600] loss: 0.602\n",
      "[12,  1700] loss: 0.637\n",
      "[12,  1800] loss: 0.619\n",
      "[13,   100] loss: 0.576\n",
      "[13,   200] loss: 0.713\n",
      "[13,   300] loss: 0.765\n",
      "[13,   400] loss: 0.707\n",
      "[13,   500] loss: 0.640\n",
      "[13,   600] loss: 0.642\n",
      "[13,   700] loss: 0.616\n",
      "[13,   800] loss: 0.616\n",
      "[13,   900] loss: 0.629\n",
      "[13,  1000] loss: 0.617\n",
      "[13,  1100] loss: 0.618\n",
      "[13,  1200] loss: 0.594\n",
      "[13,  1300] loss: 0.694\n",
      "[13,  1400] loss: 0.782\n",
      "[13,  1500] loss: 0.640\n",
      "[13,  1600] loss: 0.551\n",
      "[13,  1700] loss: 0.633\n",
      "[13,  1800] loss: 0.647\n",
      "[13,  1900] loss: 0.610\n",
      "[14,   100] loss: 0.787\n",
      "[14,   200] loss: 0.652\n",
      "[14,   300] loss: 0.675\n",
      "[14,   400] loss: 0.664\n",
      "[14,   500] loss: 0.723\n",
      "[14,   600] loss: 0.698\n",
      "[14,   700] loss: 0.656\n",
      "[14,   800] loss: 0.630\n",
      "[14,   900] loss: 0.604\n",
      "[14,  1000] loss: 0.536\n",
      "[14,  1100] loss: 0.738\n",
      "[14,  1200] loss: 0.702\n",
      "[14,  1300] loss: 0.630\n",
      "[14,  1400] loss: 0.690\n",
      "[14,  1500] loss: 0.724\n",
      "[14,  1600] loss: 0.741\n",
      "[14,  1700] loss: 0.701\n",
      "[14,  1800] loss: 0.698\n",
      "[14,  1900] loss: 0.708\n",
      "Error: Unexpected result string*\n",
      "[15,   100] loss: 0.671\n",
      "[15,   200] loss: 0.651\n",
      "[15,   300] loss: 0.622\n",
      "[15,   400] loss: 0.751\n",
      "[15,   500] loss: 0.895\n",
      "[15,   600] loss: 0.694\n",
      "[15,   700] loss: 0.733\n",
      "[15,   800] loss: 0.608\n",
      "[15,   900] loss: 0.620\n",
      "[15,  1000] loss: 0.646\n",
      "[15,  1100] loss: 0.623\n",
      "[15,  1200] loss: 0.566\n",
      "[15,  1300] loss: 0.810\n",
      "[15,  1400] loss: 0.712\n",
      "[15,  1500] loss: 0.672\n",
      "[15,  1600] loss: 0.697\n",
      "[15,  1700] loss: 0.590\n",
      "[15,  1800] loss: 0.591\n",
      "[15,  1900] loss: 0.635\n",
      "Error: Unexpected result string*\n",
      "[16,   100] loss: 0.670\n",
      "[16,   200] loss: 0.537\n",
      "[16,   300] loss: 0.591\n",
      "[16,   400] loss: 0.640\n",
      "[16,   500] loss: 0.622\n",
      "[16,   600] loss: 0.608\n",
      "[16,   700] loss: 0.660\n",
      "[16,   800] loss: 0.683\n",
      "[16,   900] loss: 0.638\n",
      "[16,  1000] loss: 0.621\n",
      "[16,  1100] loss: 0.585\n",
      "[16,  1200] loss: 0.607\n",
      "[16,  1300] loss: 0.650\n",
      "[16,  1400] loss: 0.666\n",
      "[16,  1500] loss: 0.584\n",
      "[16,  1600] loss: 0.614\n",
      "[16,  1700] loss: 0.518\n",
      "[16,  1800] loss: 0.629\n",
      "[16,  1900] loss: 0.581\n",
      "[17,   100] loss: 0.610\n",
      "[17,   200] loss: 0.580\n",
      "[17,   300] loss: 0.569\n",
      "[17,   400] loss: 0.712\n",
      "[17,   500] loss: 0.650\n",
      "[17,   600] loss: 0.615\n",
      "[17,   700] loss: 0.640\n",
      "[17,   800] loss: 0.647\n",
      "[17,   900] loss: 0.581\n",
      "[17,  1000] loss: 0.641\n",
      "[17,  1100] loss: 0.579\n",
      "[17,  1200] loss: 0.561\n",
      "[17,  1300] loss: 0.623\n",
      "[17,  1400] loss: 0.628\n",
      "[17,  1500] loss: 0.654\n",
      "[17,  1600] loss: 0.605\n",
      "[17,  1700] loss: 0.678\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "[18,   100] loss: 0.583\n",
      "[18,   200] loss: 0.679\n",
      "[18,   300] loss: 0.619\n",
      "[18,   400] loss: 0.636\n",
      "[18,   500] loss: 0.658\n",
      "[18,   600] loss: 0.575\n",
      "[18,   700] loss: 0.593\n",
      "[18,   800] loss: 0.577\n",
      "[18,   900] loss: 0.593\n",
      "[18,  1000] loss: 0.636\n",
      "[18,  1100] loss: 0.674\n",
      "[18,  1200] loss: 0.577\n",
      "[18,  1300] loss: 0.678\n",
      "[18,  1400] loss: 0.546\n",
      "[18,  1500] loss: 0.599\n",
      "[18,  1600] loss: 0.578\n",
      "[18,  1700] loss: 0.492\n",
      "[18,  1800] loss: 0.658\n",
      "[18,  1900] loss: 0.705\n",
      "[19,   100] loss: 0.735\n",
      "[19,   200] loss: 0.745\n",
      "[19,   300] loss: 0.628\n",
      "[19,   400] loss: 0.702\n",
      "[19,   500] loss: 0.703\n",
      "[19,   600] loss: 0.613\n",
      "[19,   700] loss: 0.664\n",
      "[19,   800] loss: 0.577\n",
      "[19,   900] loss: 0.687\n",
      "[19,  1000] loss: 0.711\n",
      "[19,  1100] loss: 0.625\n",
      "[19,  1200] loss: 0.726\n",
      "[19,  1300] loss: 0.643\n",
      "[19,  1400] loss: 0.686\n",
      "[19,  1500] loss: 0.741\n",
      "[19,  1600] loss: 0.662\n",
      "[19,  1700] loss: 0.585\n",
      "[19,  1800] loss: 0.548\n",
      "[19,  1900] loss: 0.680\n",
      "[20,   100] loss: 0.712\n",
      "[20,   200] loss: 0.588\n",
      "[20,   300] loss: 0.600\n",
      "[20,   400] loss: 0.720\n",
      "[20,   500] loss: 0.640\n",
      "[20,   600] loss: 0.678\n",
      "[20,   700] loss: 0.653\n",
      "[20,   800] loss: 0.754\n",
      "[20,   900] loss: 0.647\n",
      "[20,  1000] loss: 0.652\n",
      "[20,  1100] loss: 0.711\n",
      "[20,  1200] loss: 0.653\n",
      "[20,  1300] loss: 0.694\n",
      "[20,  1400] loss: 0.581\n",
      "[20,  1500] loss: 0.699\n",
      "[20,  1600] loss: 0.744\n",
      "[20,  1700] loss: 0.503\n",
      "[20,  1800] loss: 0.550\n",
      "[20,  1900] loss: 0.627\n",
      "[21,   100] loss: 0.606\n",
      "[21,   200] loss: 0.679\n",
      "[21,   300] loss: 0.597\n",
      "[21,   400] loss: 0.554\n",
      "[21,   500] loss: 0.656\n",
      "[21,   600] loss: 0.640\n",
      "[21,   700] loss: 0.579\n",
      "[21,   800] loss: 0.621\n",
      "[21,   900] loss: 0.728\n",
      "[21,  1000] loss: 0.641\n",
      "[21,  1100] loss: 0.654\n",
      "[21,  1200] loss: 0.664\n",
      "[21,  1300] loss: 0.700\n",
      "[21,  1400] loss: 0.576\n",
      "[21,  1500] loss: 0.624\n",
      "[21,  1600] loss: 0.561\n",
      "[21,  1700] loss: 0.619\n",
      "[21,  1800] loss: 0.635\n",
      "Error: Unexpected result string*\n",
      "[22,   100] loss: 0.736\n",
      "[22,   200] loss: 0.639\n",
      "[22,   300] loss: 0.642\n",
      "[22,   400] loss: 0.743\n",
      "[22,   500] loss: 0.641\n",
      "[22,   600] loss: 0.673\n",
      "[22,   700] loss: 0.605\n",
      "[22,   800] loss: 0.681\n",
      "[22,   900] loss: 0.552\n",
      "[22,  1000] loss: 0.661\n",
      "[22,  1100] loss: 0.653\n",
      "[22,  1200] loss: 0.673\n",
      "[22,  1300] loss: 0.640\n",
      "[22,  1400] loss: 0.597\n",
      "[22,  1500] loss: 0.678\n",
      "[22,  1600] loss: 0.644\n",
      "[22,  1700] loss: 0.644\n",
      "[22,  1800] loss: 0.656\n",
      "[22,  1900] loss: 0.564\n",
      "Error: Unexpected result string*\n",
      "[23,   100] loss: 0.641\n",
      "[23,   200] loss: 0.701\n",
      "[23,   300] loss: 0.594\n",
      "[23,   400] loss: 0.557\n",
      "[23,   500] loss: 0.791\n",
      "[23,   600] loss: 0.597\n",
      "[23,   700] loss: 0.627\n",
      "[23,   800] loss: 0.641\n",
      "[23,   900] loss: 0.645\n",
      "[23,  1000] loss: 0.580\n",
      "[23,  1100] loss: 0.667\n",
      "[23,  1200] loss: 0.672\n",
      "[23,  1300] loss: 0.635\n",
      "[23,  1400] loss: 0.562\n",
      "[23,  1500] loss: 0.655\n",
      "[23,  1600] loss: 0.669\n",
      "[23,  1700] loss: 0.724\n",
      "[23,  1800] loss: 0.661\n",
      "[24,   100] loss: 0.707\n",
      "[24,   200] loss: 0.602\n",
      "[24,   300] loss: 0.596\n",
      "[24,   400] loss: 0.546\n",
      "[24,   500] loss: 0.668\n",
      "[24,   600] loss: 0.646\n",
      "[24,   700] loss: 0.510\n",
      "[24,   800] loss: 0.753\n",
      "[24,   900] loss: 0.676\n",
      "[24,  1000] loss: 0.739\n",
      "[24,  1100] loss: 0.649\n",
      "[24,  1200] loss: 0.534\n",
      "[24,  1300] loss: 0.724\n",
      "[24,  1400] loss: 0.635\n",
      "[24,  1500] loss: 0.774\n",
      "[24,  1600] loss: 0.643\n",
      "[24,  1700] loss: 0.573\n",
      "[24,  1800] loss: 0.604\n",
      "[25,   100] loss: 0.620\n",
      "[25,   200] loss: 0.548\n",
      "[25,   300] loss: 0.622\n",
      "[25,   400] loss: 0.562\n",
      "[25,   500] loss: 0.661\n",
      "[25,   600] loss: 0.630\n",
      "[25,   700] loss: 0.589\n",
      "[25,   800] loss: 0.573\n",
      "[25,   900] loss: 0.591\n",
      "[25,  1000] loss: 0.619\n",
      "[25,  1100] loss: 0.706\n",
      "[25,  1200] loss: 0.722\n",
      "[25,  1300] loss: 0.555\n",
      "[25,  1400] loss: 0.775\n",
      "[25,  1500] loss: 0.584\n",
      "[25,  1600] loss: 0.616\n",
      "[25,  1700] loss: 0.682\n",
      "[25,  1800] loss: 0.613\n",
      "[25,  1900] loss: 0.519\n",
      "Error: Unexpected result string*\n",
      "[26,   100] loss: 0.628\n",
      "[26,   200] loss: 0.702\n",
      "[26,   300] loss: 0.722\n",
      "[26,   400] loss: 0.578\n",
      "[26,   500] loss: 0.657\n",
      "[26,   600] loss: 0.683\n",
      "[26,   700] loss: 0.716\n",
      "[26,   800] loss: 0.652\n",
      "[26,   900] loss: 0.599\n",
      "[26,  1000] loss: 0.669\n",
      "[26,  1100] loss: 0.701\n",
      "[26,  1200] loss: 0.538\n",
      "[26,  1300] loss: 0.621\n",
      "[26,  1400] loss: 0.750\n",
      "[26,  1500] loss: 0.629\n",
      "[26,  1600] loss: 0.634\n",
      "[26,  1700] loss: 0.739\n",
      "[26,  1800] loss: 0.681\n",
      "[26,  1900] loss: 0.677\n",
      "[27,   100] loss: 0.706\n",
      "[27,   200] loss: 0.637\n",
      "[27,   300] loss: 0.740\n",
      "[27,   400] loss: 0.543\n",
      "[27,   500] loss: 0.766\n",
      "[27,   600] loss: 0.569\n",
      "[27,   700] loss: 0.634\n",
      "[27,   800] loss: 0.503\n",
      "[27,   900] loss: 0.652\n",
      "[27,  1000] loss: 0.609\n",
      "[27,  1100] loss: 0.719\n",
      "[27,  1200] loss: 0.704\n",
      "[27,  1300] loss: 0.663\n",
      "[27,  1400] loss: 0.666\n",
      "[27,  1500] loss: 0.696\n",
      "[27,  1600] loss: 0.717\n",
      "[27,  1700] loss: 0.665\n",
      "[27,  1800] loss: 0.571\n",
      "[28,   100] loss: 0.600\n",
      "[28,   200] loss: 0.619\n",
      "[28,   300] loss: 0.604\n",
      "[28,   400] loss: 0.587\n",
      "[28,   500] loss: 0.609\n",
      "[28,   600] loss: 0.553\n",
      "[28,   700] loss: 0.633\n",
      "[28,   800] loss: 0.691\n",
      "[28,   900] loss: 0.648\n",
      "[28,  1000] loss: 0.627\n",
      "[28,  1100] loss: 0.578\n",
      "[28,  1200] loss: 0.678\n",
      "[28,  1300] loss: 0.660\n",
      "[28,  1400] loss: 0.683\n",
      "[28,  1500] loss: 0.576\n",
      "[28,  1600] loss: 0.609\n",
      "[28,  1700] loss: 0.649\n",
      "[28,  1800] loss: 0.515\n",
      "[28,  1900] loss: 0.617\n",
      "[29,   100] loss: 0.551\n",
      "[29,   200] loss: 0.542\n",
      "[29,   300] loss: 0.518\n",
      "[29,   400] loss: 0.563\n",
      "[29,   500] loss: 0.609\n",
      "[29,   600] loss: 0.535\n",
      "[29,   700] loss: 0.635\n",
      "[29,   800] loss: 0.696\n",
      "[29,   900] loss: 0.643\n",
      "[29,  1000] loss: 0.554\n",
      "[29,  1100] loss: 0.558\n",
      "[29,  1200] loss: 0.661\n",
      "[29,  1300] loss: 0.540\n",
      "[29,  1400] loss: 0.566\n",
      "[29,  1500] loss: 0.620\n",
      "[29,  1600] loss: 0.524\n",
      "[29,  1700] loss: 0.568\n",
      "[29,  1800] loss: 0.544\n",
      "[29,  1900] loss: 0.708\n",
      "Error: Unexpected result string*\n",
      "[30,   100] loss: 0.667\n",
      "[30,   200] loss: 0.615\n",
      "[30,   300] loss: 0.587\n",
      "[30,   400] loss: 0.621\n",
      "[30,   500] loss: 0.608\n",
      "[30,   600] loss: 0.683\n",
      "[30,   700] loss: 0.493\n",
      "[30,   800] loss: 0.643\n",
      "[30,   900] loss: 0.650\n",
      "[30,  1000] loss: 0.612\n",
      "[30,  1100] loss: 0.640\n",
      "[30,  1200] loss: 0.651\n",
      "[30,  1300] loss: 0.722\n",
      "[30,  1400] loss: 0.597\n",
      "[30,  1500] loss: 0.638\n",
      "[30,  1600] loss: 0.615\n",
      "[30,  1700] loss: 0.642\n",
      "[30,  1800] loss: 0.687\n",
      "[31,   100] loss: 0.754\n",
      "[31,   200] loss: 0.634\n",
      "[31,   300] loss: 0.693\n",
      "[31,   400] loss: 0.583\n",
      "[31,   500] loss: 0.543\n",
      "[31,   600] loss: 0.643\n",
      "[31,   700] loss: 0.602\n",
      "[31,   800] loss: 0.713\n",
      "[31,   900] loss: 0.701\n",
      "[31,  1000] loss: 0.641\n",
      "[31,  1100] loss: 0.701\n",
      "[31,  1200] loss: 0.661\n",
      "[31,  1300] loss: 0.660\n",
      "[31,  1400] loss: 0.640\n",
      "[31,  1500] loss: 0.705\n",
      "[31,  1600] loss: 0.673\n",
      "[31,  1700] loss: 0.647\n",
      "[31,  1800] loss: 0.664\n",
      "[32,   100] loss: 0.557\n",
      "[32,   200] loss: 0.573\n",
      "[32,   300] loss: 0.598\n",
      "[32,   400] loss: 0.641\n",
      "[32,   500] loss: 0.632\n",
      "[32,   600] loss: 0.634\n",
      "[32,   700] loss: 0.603\n",
      "[32,   800] loss: 0.672\n",
      "[32,   900] loss: 0.589\n",
      "[32,  1000] loss: 0.503\n",
      "[32,  1100] loss: 0.741\n",
      "[32,  1200] loss: 0.702\n",
      "[32,  1300] loss: 0.678\n",
      "[32,  1400] loss: 0.608\n",
      "[32,  1500] loss: 0.580\n",
      "[32,  1600] loss: 0.589\n",
      "[32,  1700] loss: 0.697\n",
      "[32,  1800] loss: 0.621\n",
      "[32,  1900] loss: 0.634\n",
      "[33,   100] loss: 0.636\n",
      "[33,   200] loss: 0.773\n",
      "[33,   300] loss: 0.591\n",
      "[33,   400] loss: 0.587\n",
      "[33,   500] loss: 0.581\n",
      "[33,   600] loss: 0.636\n",
      "[33,   700] loss: 0.709\n",
      "[33,   800] loss: 0.647\n",
      "[33,   900] loss: 0.621\n",
      "[33,  1000] loss: 0.685\n",
      "[33,  1100] loss: 0.635\n",
      "[33,  1200] loss: 0.578\n",
      "[33,  1300] loss: 0.686\n",
      "[33,  1400] loss: 0.694\n",
      "[33,  1500] loss: 0.622\n",
      "[33,  1600] loss: 0.646\n",
      "[33,  1700] loss: 0.648\n",
      "[33,  1800] loss: 0.651\n",
      "[34,   100] loss: 0.669\n",
      "[34,   200] loss: 0.674\n",
      "[34,   300] loss: 0.630\n",
      "[34,   400] loss: 0.609\n",
      "[34,   500] loss: 0.595\n",
      "[34,   600] loss: 0.600\n",
      "[34,   700] loss: 0.546\n",
      "[34,   800] loss: 0.623\n",
      "[34,   900] loss: 0.589\n",
      "[34,  1000] loss: 0.629\n",
      "[34,  1100] loss: 0.642\n",
      "[34,  1200] loss: 0.571\n",
      "[34,  1300] loss: 0.592\n",
      "[34,  1400] loss: 0.586\n",
      "[34,  1500] loss: 0.545\n",
      "[34,  1600] loss: 0.638\n",
      "[34,  1700] loss: 0.584\n",
      "[34,  1800] loss: 0.530\n",
      "[34,  1900] loss: 0.577\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "[35,   100] loss: 0.647\n",
      "[35,   200] loss: 0.579\n",
      "[35,   300] loss: 0.635\n",
      "[35,   400] loss: 0.688\n",
      "[35,   500] loss: 0.633\n",
      "[35,   600] loss: 0.657\n",
      "[35,   700] loss: 0.610\n",
      "[35,   800] loss: 0.678\n",
      "[35,   900] loss: 0.666\n",
      "[35,  1000] loss: 0.672\n",
      "[35,  1100] loss: 0.616\n",
      "[35,  1200] loss: 0.583\n",
      "[35,  1300] loss: 0.620\n",
      "[35,  1400] loss: 0.700\n",
      "[35,  1500] loss: 0.634\n",
      "[35,  1600] loss: 0.681\n",
      "[35,  1700] loss: 0.647\n",
      "[35,  1800] loss: 0.617\n",
      "[36,   100] loss: 0.580\n",
      "[36,   200] loss: 0.657\n",
      "[36,   300] loss: 0.735\n",
      "[36,   400] loss: 0.618\n",
      "[36,   500] loss: 0.646\n",
      "[36,   600] loss: 0.609\n",
      "[36,   700] loss: 0.692\n",
      "[36,   800] loss: 0.631\n",
      "[36,   900] loss: 0.714\n",
      "[36,  1000] loss: 0.703\n",
      "[36,  1100] loss: 0.643\n",
      "[36,  1200] loss: 0.593\n",
      "[36,  1300] loss: 0.698\n",
      "[36,  1400] loss: 0.642\n",
      "[36,  1500] loss: 0.763\n",
      "[36,  1600] loss: 0.606\n",
      "[36,  1700] loss: 0.593\n",
      "[36,  1800] loss: 0.530\n",
      "[37,   100] loss: 0.733\n",
      "[37,   200] loss: 0.600\n",
      "[37,   300] loss: 0.698\n",
      "[37,   400] loss: 0.778\n",
      "[37,   500] loss: 0.746\n",
      "[37,   600] loss: 0.822\n",
      "[37,   700] loss: 0.808\n",
      "[37,   800] loss: 0.660\n",
      "[37,   900] loss: 0.701\n",
      "[37,  1000] loss: 0.685\n",
      "[37,  1100] loss: 0.674\n",
      "[37,  1200] loss: 0.723\n",
      "[37,  1300] loss: 0.708\n",
      "[37,  1400] loss: 0.696\n",
      "[37,  1500] loss: 0.726\n",
      "[37,  1600] loss: 0.732\n",
      "[37,  1700] loss: 0.602\n",
      "[37,  1800] loss: 0.738\n",
      "[38,   100] loss: 0.625\n",
      "[38,   200] loss: 0.674\n",
      "[38,   300] loss: 0.595\n",
      "[38,   400] loss: 0.650\n",
      "[38,   500] loss: 0.822\n",
      "[38,   600] loss: 0.655\n",
      "[38,   700] loss: 0.646\n",
      "[38,   800] loss: 0.623\n",
      "[38,   900] loss: 0.590\n",
      "[38,  1000] loss: 0.597\n",
      "[38,  1100] loss: 0.628\n",
      "[38,  1200] loss: 0.705\n",
      "[38,  1300] loss: 0.571\n",
      "[38,  1400] loss: 0.819\n",
      "[38,  1500] loss: 0.628\n",
      "[38,  1600] loss: 0.650\n",
      "[38,  1700] loss: 0.585\n",
      "[38,  1800] loss: 0.652\n",
      "[38,  1900] loss: 0.623\n",
      "Error: Unexpected result string*\n",
      "[39,   100] loss: 0.543\n",
      "[39,   200] loss: 0.601\n",
      "[39,   300] loss: 0.624\n",
      "[39,   400] loss: 0.686\n",
      "[39,   500] loss: 0.651\n",
      "[39,   600] loss: 0.639\n",
      "[39,   700] loss: 0.640\n",
      "[39,   800] loss: 0.660\n",
      "[39,   900] loss: 0.614\n",
      "[39,  1000] loss: 0.710\n",
      "[39,  1100] loss: 0.609\n",
      "[39,  1200] loss: 0.807\n",
      "[39,  1300] loss: 0.683\n",
      "[39,  1400] loss: 0.628\n",
      "[39,  1500] loss: 0.708\n",
      "[39,  1600] loss: 0.650\n",
      "[39,  1700] loss: 0.601\n",
      "[39,  1800] loss: 0.565\n",
      "[39,  1900] loss: 0.697\n",
      "Error: Unexpected result string*\n",
      "[40,   100] loss: 0.617\n",
      "[40,   200] loss: 0.658\n",
      "[40,   300] loss: 0.707\n",
      "[40,   400] loss: 0.554\n",
      "[40,   500] loss: 0.620\n",
      "[40,   600] loss: 0.612\n",
      "[40,   700] loss: 0.587\n",
      "[40,   800] loss: 0.586\n",
      "[40,   900] loss: 0.538\n",
      "[40,  1000] loss: 0.620\n",
      "[40,  1100] loss: 0.556\n",
      "[40,  1200] loss: 0.649\n",
      "[40,  1300] loss: 0.685\n",
      "[40,  1400] loss: 0.622\n",
      "[40,  1500] loss: 0.493\n",
      "[40,  1600] loss: 0.556\n",
      "[40,  1700] loss: 0.555\n",
      "[40,  1800] loss: 0.605\n",
      "Error: Unexpected result string*\n",
      "[41,   100] loss: 0.702\n",
      "[41,   200] loss: 0.709\n",
      "[41,   300] loss: 0.572\n",
      "[41,   400] loss: 0.732\n",
      "[41,   500] loss: 0.577\n",
      "[41,   600] loss: 0.622\n",
      "[41,   700] loss: 0.704\n",
      "[41,   800] loss: 0.655\n",
      "[41,   900] loss: 0.615\n",
      "[41,  1000] loss: 0.701\n",
      "[41,  1100] loss: 0.667\n",
      "[41,  1200] loss: 0.528\n",
      "[41,  1300] loss: 0.635\n",
      "[41,  1400] loss: 0.709\n",
      "[41,  1500] loss: 0.626\n",
      "[41,  1600] loss: 0.659\n",
      "[41,  1700] loss: 0.630\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "[42,   100] loss: 0.692\n",
      "[42,   200] loss: 0.636\n",
      "[42,   300] loss: 0.594\n",
      "[42,   400] loss: 0.677\n",
      "[42,   500] loss: 0.657\n",
      "[42,   600] loss: 0.609\n",
      "[42,   700] loss: 0.618\n",
      "[42,   800] loss: 0.655\n",
      "[42,   900] loss: 0.660\n",
      "[42,  1000] loss: 0.699\n",
      "[42,  1100] loss: 0.712\n",
      "[42,  1200] loss: 0.611\n",
      "[42,  1300] loss: 0.659\n",
      "[42,  1400] loss: 0.649\n",
      "[42,  1500] loss: 0.559\n",
      "[42,  1600] loss: 0.533\n",
      "[42,  1700] loss: 0.679\n",
      "[42,  1800] loss: 0.683\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "[43,   100] loss: 0.635\n",
      "[43,   200] loss: 0.662\n",
      "[43,   300] loss: 0.560\n",
      "[43,   400] loss: 0.567\n",
      "[43,   500] loss: 0.605\n",
      "[43,   600] loss: 0.531\n",
      "[43,   700] loss: 0.635\n",
      "[43,   800] loss: 0.580\n",
      "[43,   900] loss: 0.535\n",
      "[43,  1000] loss: 0.639\n",
      "[43,  1100] loss: 0.547\n",
      "[43,  1200] loss: 0.635\n",
      "[43,  1300] loss: 0.626\n",
      "[43,  1400] loss: 0.568\n",
      "[43,  1500] loss: 0.595\n",
      "[43,  1600] loss: 0.471\n",
      "[43,  1700] loss: 0.521\n",
      "[43,  1800] loss: 0.534\n",
      "[43,  1900] loss: 0.645\n",
      "[44,   100] loss: 0.615\n",
      "[44,   200] loss: 0.669\n",
      "[44,   300] loss: 0.690\n",
      "[44,   400] loss: 0.586\n",
      "[44,   500] loss: 0.543\n",
      "[44,   600] loss: 0.633\n",
      "[44,   700] loss: 0.654\n",
      "[44,   800] loss: 0.602\n",
      "[44,   900] loss: 0.647\n",
      "[44,  1000] loss: 0.551\n",
      "[44,  1100] loss: 0.698\n",
      "[44,  1200] loss: 0.646\n",
      "[44,  1300] loss: 0.602\n",
      "[44,  1400] loss: 0.596\n",
      "[44,  1500] loss: 0.592\n",
      "[44,  1600] loss: 0.620\n",
      "[44,  1700] loss: 0.620\n",
      "[44,  1800] loss: 0.627\n",
      "[44,  1900] loss: 0.565\n",
      "[45,   100] loss: 0.690\n",
      "[45,   200] loss: 0.537\n",
      "[45,   300] loss: 0.580\n",
      "[45,   400] loss: 0.657\n",
      "[45,   500] loss: 0.521\n",
      "[45,   600] loss: 0.724\n",
      "[45,   700] loss: 0.624\n",
      "[45,   800] loss: 0.603\n",
      "[45,   900] loss: 0.542\n",
      "[45,  1000] loss: 0.703\n",
      "[45,  1100] loss: 0.607\n",
      "[45,  1200] loss: 0.594\n",
      "[45,  1300] loss: 0.555\n",
      "[45,  1400] loss: 0.614\n",
      "[45,  1500] loss: 0.600\n",
      "[45,  1600] loss: 0.702\n",
      "[45,  1700] loss: 0.564\n",
      "[45,  1800] loss: 0.595\n",
      "Error: Unexpected result string*\n",
      "[46,   100] loss: 0.682\n",
      "[46,   200] loss: 0.680\n",
      "[46,   300] loss: 0.577\n",
      "[46,   400] loss: 0.649\n",
      "[46,   500] loss: 0.612\n",
      "[46,   600] loss: 0.590\n",
      "[46,   700] loss: 0.667\n",
      "[46,   800] loss: 0.606\n",
      "[46,   900] loss: 0.676\n",
      "[46,  1000] loss: 0.632\n",
      "[46,  1100] loss: 0.718\n",
      "[46,  1200] loss: 0.615\n",
      "[46,  1300] loss: 0.534\n",
      "[46,  1400] loss: 0.507\n",
      "[46,  1500] loss: 0.756\n",
      "[46,  1600] loss: 0.760\n",
      "[46,  1700] loss: 0.671\n",
      "Error: Unexpected result string*\n",
      "[47,   100] loss: 0.581\n",
      "[47,   200] loss: 0.702\n",
      "[47,   300] loss: 0.637\n",
      "[47,   400] loss: 0.603\n",
      "[47,   500] loss: 0.642\n",
      "[47,   600] loss: 0.588\n",
      "[47,   700] loss: 0.674\n",
      "[47,   800] loss: 0.599\n",
      "[47,   900] loss: 0.684\n",
      "[47,  1000] loss: 0.558\n",
      "[47,  1100] loss: 0.636\n",
      "[47,  1200] loss: 0.525\n",
      "[47,  1300] loss: 0.624\n",
      "[47,  1400] loss: 0.684\n",
      "[47,  1500] loss: 0.670\n",
      "[47,  1600] loss: 0.651\n",
      "[47,  1700] loss: 0.477\n",
      "[47,  1800] loss: 0.677\n",
      "Error: Unexpected result string*\n",
      "[48,   100] loss: 0.627\n",
      "[48,   200] loss: 0.675\n",
      "[48,   300] loss: 0.729\n",
      "[48,   400] loss: 0.682\n",
      "[48,   500] loss: 0.677\n",
      "[48,   600] loss: 0.679\n",
      "[48,   700] loss: 0.819\n",
      "[48,   800] loss: 0.746\n",
      "[48,   900] loss: 0.672\n",
      "[48,  1000] loss: 0.641\n",
      "[48,  1100] loss: 0.751\n",
      "[48,  1200] loss: 0.631\n",
      "[48,  1300] loss: 0.608\n",
      "[48,  1400] loss: 0.631\n",
      "[48,  1500] loss: 0.605\n",
      "[48,  1600] loss: 0.664\n",
      "[48,  1700] loss: 0.695\n",
      "[48,  1800] loss: 0.744\n",
      "Error: Unexpected result string*\n",
      "[49,   100] loss: 0.599\n",
      "[49,   200] loss: 0.613\n",
      "[49,   300] loss: 0.536\n",
      "[49,   400] loss: 0.571\n",
      "[49,   500] loss: 0.609\n",
      "[49,   600] loss: 0.453\n",
      "[49,   700] loss: 0.596\n",
      "[49,   800] loss: 0.582\n",
      "[49,   900] loss: 0.559\n",
      "[49,  1000] loss: 0.433\n",
      "[49,  1100] loss: 0.622\n",
      "[49,  1200] loss: 0.638\n",
      "[49,  1300] loss: 0.520\n",
      "[49,  1400] loss: 0.626\n",
      "[49,  1500] loss: 0.503\n",
      "[49,  1600] loss: 0.552\n",
      "[49,  1700] loss: 0.532\n",
      "[49,  1800] loss: 0.604\n",
      "[49,  1900] loss: 0.485\n",
      "[50,   100] loss: 0.566\n",
      "[50,   200] loss: 0.582\n",
      "[50,   300] loss: 0.673\n",
      "[50,   400] loss: 0.718\n",
      "[50,   500] loss: 0.699\n",
      "[50,   600] loss: 0.611\n",
      "[50,   700] loss: 0.594\n",
      "[50,   800] loss: 0.659\n",
      "[50,   900] loss: 0.650\n",
      "[50,  1000] loss: 0.599\n",
      "[50,  1100] loss: 0.653\n",
      "[50,  1200] loss: 0.656\n",
      "[50,  1300] loss: 0.612\n",
      "[50,  1400] loss: 0.642\n",
      "[50,  1500] loss: 0.745\n",
      "[50,  1600] loss: 0.657\n",
      "[50,  1700] loss: 0.653\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "[51,   100] loss: 0.558\n",
      "[51,   200] loss: 0.615\n",
      "[51,   300] loss: 0.598\n",
      "[51,   400] loss: 0.537\n",
      "[51,   500] loss: 0.586\n",
      "[51,   600] loss: 0.666\n",
      "[51,   700] loss: 0.596\n",
      "[51,   800] loss: 0.631\n",
      "[51,   900] loss: 0.583\n",
      "[51,  1000] loss: 0.536\n",
      "[51,  1100] loss: 0.519\n",
      "[51,  1200] loss: 0.634\n",
      "[51,  1300] loss: 0.670\n",
      "[51,  1400] loss: 0.528\n",
      "[51,  1500] loss: 0.613\n",
      "[51,  1600] loss: 0.669\n",
      "[51,  1700] loss: 0.628\n",
      "[51,  1800] loss: 0.710\n",
      "[51,  1900] loss: 0.603\n",
      "[52,   100] loss: 0.702\n",
      "[52,   200] loss: 0.519\n",
      "[52,   300] loss: 0.543\n",
      "[52,   400] loss: 0.693\n",
      "[52,   500] loss: 0.534\n",
      "[52,   600] loss: 0.670\n",
      "[52,   700] loss: 0.658\n",
      "[52,   800] loss: 0.595\n",
      "[52,   900] loss: 0.620\n",
      "[52,  1000] loss: 0.605\n",
      "[52,  1100] loss: 0.601\n",
      "[52,  1200] loss: 0.504\n",
      "[52,  1300] loss: 0.641\n",
      "[52,  1400] loss: 0.677\n",
      "[52,  1500] loss: 0.605\n",
      "[52,  1600] loss: 0.705\n",
      "[52,  1700] loss: 0.584\n",
      "[52,  1800] loss: 0.529\n",
      "[52,  1900] loss: 0.577\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "[53,   100] loss: 0.614\n",
      "[53,   200] loss: 0.599\n",
      "[53,   300] loss: 0.631\n",
      "[53,   400] loss: 0.745\n",
      "[53,   500] loss: 0.640\n",
      "[53,   600] loss: 0.664\n",
      "[53,   700] loss: 0.673\n",
      "[53,   800] loss: 0.566\n",
      "[53,   900] loss: 0.628\n",
      "[53,  1000] loss: 0.545\n",
      "[53,  1100] loss: 0.580\n",
      "[53,  1200] loss: 0.620\n",
      "[53,  1300] loss: 0.635\n",
      "[53,  1400] loss: 0.544\n",
      "[53,  1500] loss: 0.640\n",
      "[53,  1600] loss: 0.689\n",
      "[53,  1700] loss: 0.707\n",
      "[53,  1800] loss: 0.627\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "[54,   100] loss: 0.503\n",
      "[54,   200] loss: 0.584\n",
      "[54,   300] loss: 0.613\n",
      "[54,   400] loss: 0.595\n",
      "[54,   500] loss: 0.657\n",
      "[54,   600] loss: 0.564\n",
      "[54,   700] loss: 0.554\n",
      "[54,   800] loss: 0.557\n",
      "[54,   900] loss: 0.557\n",
      "[54,  1000] loss: 0.586\n",
      "[54,  1100] loss: 0.583\n",
      "[54,  1200] loss: 0.617\n",
      "[54,  1300] loss: 0.564\n",
      "[54,  1400] loss: 0.595\n",
      "[54,  1500] loss: 0.570\n",
      "[54,  1600] loss: 0.491\n",
      "[54,  1700] loss: 0.557\n",
      "[54,  1800] loss: 0.565\n",
      "Error: Unexpected result string*\n",
      "[55,   100] loss: 0.621\n",
      "[55,   200] loss: 0.625\n",
      "[55,   300] loss: 0.577\n",
      "[55,   400] loss: 0.632\n",
      "[55,   500] loss: 0.562\n",
      "[55,   600] loss: 0.576\n",
      "[55,   700] loss: 0.590\n",
      "[55,   800] loss: 0.631\n",
      "[55,   900] loss: 0.622\n",
      "[55,  1000] loss: 0.680\n",
      "[55,  1100] loss: 0.781\n",
      "[55,  1200] loss: 0.615\n",
      "[55,  1300] loss: 0.509\n",
      "[55,  1400] loss: 0.532\n",
      "[55,  1500] loss: 0.622\n",
      "[55,  1600] loss: 0.579\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "[56,   100] loss: 0.639\n",
      "[56,   200] loss: 0.639\n",
      "[56,   300] loss: 0.597\n",
      "[56,   400] loss: 0.610\n",
      "[56,   500] loss: 0.532\n",
      "[56,   600] loss: 0.646\n",
      "[56,   700] loss: 0.545\n",
      "[56,   800] loss: 0.638\n",
      "[56,   900] loss: 0.674\n",
      "[56,  1000] loss: 0.588\n",
      "[56,  1100] loss: 0.440\n",
      "[56,  1200] loss: 0.611\n",
      "[56,  1300] loss: 0.620\n",
      "[56,  1400] loss: 0.582\n",
      "[56,  1500] loss: 0.603\n",
      "[56,  1600] loss: 0.666\n",
      "[56,  1700] loss: 0.514\n",
      "[56,  1800] loss: 0.686\n",
      "[56,  1900] loss: 0.583\n",
      "[57,   100] loss: 0.653\n",
      "[57,   200] loss: 0.664\n",
      "[57,   300] loss: 0.507\n",
      "[57,   400] loss: 0.620\n",
      "[57,   500] loss: 0.637\n",
      "[57,   600] loss: 0.592\n",
      "[57,   700] loss: 0.563\n",
      "[57,   800] loss: 0.570\n",
      "[57,   900] loss: 0.731\n",
      "[57,  1000] loss: 0.631\n",
      "[57,  1100] loss: 0.679\n",
      "[57,  1200] loss: 0.715\n",
      "[57,  1300] loss: 0.684\n",
      "[57,  1400] loss: 0.661\n",
      "[57,  1500] loss: 0.612\n",
      "[57,  1600] loss: 0.581\n",
      "Error: Unexpected result string*\n",
      "[58,   100] loss: 0.667\n",
      "[58,   200] loss: 0.561\n",
      "[58,   300] loss: 0.600\n",
      "[58,   400] loss: 0.598\n",
      "[58,   500] loss: 0.517\n",
      "[58,   600] loss: 0.545\n",
      "[58,   700] loss: 0.550\n",
      "[58,   800] loss: 0.671\n",
      "[58,   900] loss: 0.577\n",
      "[58,  1000] loss: 0.592\n",
      "[58,  1100] loss: 0.617\n",
      "[58,  1200] loss: 0.560\n",
      "[58,  1300] loss: 0.606\n",
      "[58,  1400] loss: 0.473\n",
      "[58,  1500] loss: 0.472\n",
      "[58,  1600] loss: 0.524\n",
      "[58,  1700] loss: 0.570\n",
      "[59,   100] loss: 0.581\n",
      "[59,   200] loss: 0.561\n",
      "[59,   300] loss: 0.508\n",
      "[59,   400] loss: 0.682\n",
      "[59,   500] loss: 0.615\n",
      "[59,   600] loss: 0.517\n",
      "[59,   700] loss: 0.588\n",
      "[59,   800] loss: 0.520\n",
      "[59,   900] loss: 0.608\n",
      "[59,  1000] loss: 0.638\n",
      "[59,  1100] loss: 0.584\n",
      "[59,  1200] loss: 0.688\n",
      "[59,  1300] loss: 0.565\n",
      "[59,  1400] loss: 0.539\n",
      "[59,  1500] loss: 0.576\n",
      "[59,  1600] loss: 0.588\n",
      "[59,  1700] loss: 0.521\n",
      "[59,  1800] loss: 0.585\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "[60,   100] loss: 0.580\n",
      "[60,   200] loss: 0.521\n",
      "[60,   300] loss: 0.556\n",
      "[60,   400] loss: 0.536\n",
      "[60,   500] loss: 0.629\n",
      "[60,   600] loss: 0.571\n",
      "[60,   700] loss: 0.572\n",
      "[60,   800] loss: 0.564\n",
      "[60,   900] loss: 0.656\n",
      "[60,  1000] loss: 0.502\n",
      "[60,  1100] loss: 0.610\n",
      "[60,  1200] loss: 0.576\n",
      "[60,  1300] loss: 0.603\n",
      "[60,  1400] loss: 0.670\n",
      "[60,  1500] loss: 0.600\n",
      "[60,  1600] loss: 0.630\n",
      "[60,  1700] loss: 0.559\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "[61,   100] loss: 0.531\n",
      "[61,   200] loss: 0.720\n",
      "[61,   300] loss: 0.636\n",
      "[61,   400] loss: 0.605\n",
      "[61,   500] loss: 0.650\n",
      "[61,   600] loss: 0.674\n",
      "[61,   700] loss: 0.611\n",
      "[61,   800] loss: 0.541\n",
      "[61,   900] loss: 0.654\n",
      "[61,  1000] loss: 0.650\n",
      "[61,  1100] loss: 0.570\n",
      "[61,  1200] loss: 0.692\n",
      "[61,  1300] loss: 0.563\n",
      "[61,  1400] loss: 0.553\n",
      "[61,  1500] loss: 0.528\n",
      "[61,  1600] loss: 0.659\n",
      "[61,  1700] loss: 0.702\n",
      "[61,  1800] loss: 0.550\n",
      "[62,   100] loss: 0.691\n",
      "[62,   200] loss: 0.562\n",
      "[62,   300] loss: 0.707\n",
      "[62,   400] loss: 0.618\n",
      "[62,   500] loss: 0.660\n",
      "[62,   600] loss: 0.584\n",
      "[62,   700] loss: 0.621\n",
      "[62,   800] loss: 0.546\n",
      "[62,   900] loss: 0.588\n",
      "[62,  1000] loss: 0.748\n",
      "[62,  1100] loss: 0.637\n",
      "[62,  1200] loss: 0.553\n",
      "[62,  1300] loss: 0.568\n",
      "[62,  1400] loss: 0.647\n",
      "[62,  1500] loss: 0.667\n",
      "[62,  1600] loss: 0.751\n",
      "Error: Unexpected result string*\n",
      "[63,   100] loss: 0.707\n",
      "[63,   200] loss: 0.612\n",
      "[63,   300] loss: 0.587\n",
      "[63,   400] loss: 0.732\n",
      "[63,   500] loss: 0.600\n",
      "[63,   600] loss: 0.550\n",
      "[63,   700] loss: 0.692\n",
      "[63,   800] loss: 0.665\n",
      "[63,   900] loss: 0.616\n",
      "[63,  1000] loss: 0.688\n",
      "[63,  1100] loss: 0.506\n",
      "[63,  1200] loss: 0.650\n",
      "[63,  1300] loss: 0.647\n",
      "[63,  1400] loss: 0.654\n",
      "[63,  1500] loss: 0.544\n",
      "[63,  1600] loss: 0.643\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "[64,   100] loss: 0.566\n",
      "[64,   200] loss: 0.715\n",
      "[64,   300] loss: 0.493\n",
      "[64,   400] loss: 0.626\n",
      "[64,   500] loss: 0.624\n",
      "[64,   600] loss: 0.617\n",
      "[64,   700] loss: 0.621\n",
      "[64,   800] loss: 0.685\n",
      "[64,   900] loss: 0.594\n",
      "[64,  1000] loss: 0.650\n",
      "[64,  1100] loss: 0.603\n",
      "[64,  1200] loss: 0.591\n",
      "[64,  1300] loss: 0.580\n",
      "[64,  1400] loss: 0.608\n",
      "[64,  1500] loss: 0.637\n",
      "[64,  1600] loss: 0.589\n",
      "[64,  1700] loss: 0.557\n",
      "[64,  1800] loss: 0.592\n",
      "[64,  1900] loss: 0.486\n",
      "[65,   100] loss: 0.561\n",
      "[65,   200] loss: 0.663\n",
      "[65,   300] loss: 0.626\n",
      "[65,   400] loss: 0.656\n",
      "[65,   500] loss: 0.621\n",
      "[65,   600] loss: 0.600\n",
      "[65,   700] loss: 0.627\n",
      "[65,   800] loss: 0.732\n",
      "[65,   900] loss: 0.662\n",
      "[65,  1000] loss: 0.629\n",
      "[65,  1100] loss: 0.577\n",
      "[65,  1200] loss: 0.632\n",
      "[65,  1300] loss: 0.567\n",
      "[65,  1400] loss: 0.573\n",
      "[65,  1500] loss: 0.609\n",
      "[65,  1600] loss: 0.593\n",
      "[65,  1700] loss: 0.681\n",
      "[65,  1800] loss: 0.586\n",
      "[66,   100] loss: 0.571\n",
      "[66,   200] loss: 0.657\n",
      "[66,   300] loss: 0.482\n",
      "[66,   400] loss: 0.537\n",
      "[66,   500] loss: 0.613\n",
      "[66,   600] loss: 0.591\n",
      "[66,   700] loss: 0.666\n",
      "[66,   800] loss: 0.540\n",
      "[66,   900] loss: 0.581\n",
      "[66,  1000] loss: 0.711\n",
      "[66,  1100] loss: 0.565\n",
      "[66,  1200] loss: 0.630\n",
      "[66,  1300] loss: 0.536\n",
      "[66,  1400] loss: 0.642\n",
      "[66,  1500] loss: 0.688\n",
      "[66,  1600] loss: 0.589\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "[67,   100] loss: 0.582\n",
      "[67,   200] loss: 0.595\n",
      "[67,   300] loss: 0.655\n",
      "[67,   400] loss: 0.605\n",
      "[67,   500] loss: 0.600\n",
      "[67,   600] loss: 0.646\n",
      "[67,   700] loss: 0.544\n",
      "[67,   800] loss: 0.545\n",
      "[67,   900] loss: 0.634\n",
      "[67,  1000] loss: 0.589\n",
      "[67,  1100] loss: 0.654\n",
      "[67,  1200] loss: 0.550\n",
      "[67,  1300] loss: 0.564\n",
      "[67,  1400] loss: 0.601\n",
      "[67,  1500] loss: 0.674\n",
      "[67,  1600] loss: 0.619\n",
      "[67,  1700] loss: 0.620\n",
      "[67,  1800] loss: 0.637\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "[68,   100] loss: 0.663\n",
      "[68,   200] loss: 0.581\n",
      "[68,   300] loss: 0.713\n",
      "[68,   400] loss: 0.601\n",
      "[68,   500] loss: 0.653\n",
      "[68,   600] loss: 0.698\n",
      "[68,   700] loss: 0.538\n",
      "[68,   800] loss: 0.659\n",
      "[68,   900] loss: 0.583\n",
      "[68,  1000] loss: 0.598\n",
      "[68,  1100] loss: 0.502\n",
      "[68,  1200] loss: 0.615\n",
      "[68,  1300] loss: 0.655\n",
      "[68,  1400] loss: 0.741\n",
      "[68,  1500] loss: 0.596\n",
      "[68,  1600] loss: 0.599\n",
      "[68,  1700] loss: 0.644\n",
      "Error: Unexpected result string*\n",
      "[69,   100] loss: 0.605\n",
      "[69,   200] loss: 0.621\n",
      "[69,   300] loss: 0.630\n",
      "[69,   400] loss: 0.662\n",
      "[69,   500] loss: 0.620\n",
      "[69,   600] loss: 0.675\n",
      "[69,   700] loss: 0.678\n",
      "[69,   800] loss: 0.692\n",
      "[69,   900] loss: 0.643\n",
      "[69,  1000] loss: 0.629\n",
      "[69,  1100] loss: 0.785\n",
      "[69,  1200] loss: 0.637\n",
      "[69,  1300] loss: 0.623\n",
      "[69,  1400] loss: 0.582\n",
      "[69,  1500] loss: 0.570\n",
      "[69,  1600] loss: 0.696\n",
      "[69,  1700] loss: 0.651\n",
      "Error: Unexpected result string*\n",
      "[70,   100] loss: 0.493\n",
      "[70,   200] loss: 0.582\n",
      "[70,   300] loss: 0.594\n",
      "[70,   400] loss: 0.562\n",
      "[70,   500] loss: 0.614\n",
      "[70,   600] loss: 0.615\n",
      "[70,   700] loss: 0.700\n",
      "[70,   800] loss: 0.699\n",
      "[70,   900] loss: 0.651\n",
      "[70,  1000] loss: 0.672\n",
      "[70,  1100] loss: 0.671\n",
      "[70,  1200] loss: 0.556\n",
      "[70,  1300] loss: 0.650\n",
      "[70,  1400] loss: 0.642\n",
      "[70,  1500] loss: 0.737\n",
      "[70,  1600] loss: 0.607\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "[71,   100] loss: 0.615\n",
      "[71,   200] loss: 0.647\n",
      "[71,   300] loss: 0.597\n",
      "[71,   400] loss: 0.726\n",
      "[71,   500] loss: 0.604\n",
      "[71,   600] loss: 0.563\n",
      "[71,   700] loss: 0.651\n",
      "[71,   800] loss: 0.662\n",
      "[71,   900] loss: 0.653\n",
      "[71,  1000] loss: 0.618\n",
      "[71,  1100] loss: 0.647\n",
      "[71,  1200] loss: 0.709\n",
      "[71,  1300] loss: 0.683\n",
      "[71,  1400] loss: 0.647\n",
      "[71,  1500] loss: 0.714\n",
      "[71,  1600] loss: 0.655\n",
      "Error: Unexpected result string*\n",
      "[72,   100] loss: 0.683\n",
      "[72,   200] loss: 0.590\n",
      "[72,   300] loss: 0.671\n",
      "[72,   400] loss: 0.689\n",
      "[72,   500] loss: 0.460\n",
      "[72,   600] loss: 0.484\n",
      "[72,   700] loss: 0.494\n",
      "[72,   800] loss: 0.532\n",
      "[72,   900] loss: 0.596\n",
      "[72,  1000] loss: 0.619\n",
      "[72,  1100] loss: 0.476\n",
      "[72,  1200] loss: 0.716\n",
      "[72,  1300] loss: 0.560\n",
      "[72,  1400] loss: 0.627\n",
      "[72,  1500] loss: 0.594\n",
      "[72,  1600] loss: 0.620\n",
      "[72,  1700] loss: 0.630\n",
      "[72,  1800] loss: 0.428\n",
      "[72,  1900] loss: 0.613\n",
      "[73,   100] loss: 0.684\n",
      "[73,   200] loss: 0.530\n",
      "[73,   300] loss: 0.674\n",
      "[73,   400] loss: 0.619\n",
      "[73,   500] loss: 0.591\n",
      "[73,   600] loss: 0.648\n",
      "[73,   700] loss: 0.654\n",
      "[73,   800] loss: 0.551\n",
      "[73,   900] loss: 0.658\n",
      "[73,  1000] loss: 0.638\n",
      "[73,  1100] loss: 0.635\n",
      "[73,  1200] loss: 0.696\n",
      "[73,  1300] loss: 0.568\n",
      "[73,  1400] loss: 0.653\n",
      "[74,   100] loss: 0.611\n",
      "[74,   200] loss: 0.647\n",
      "[74,   300] loss: 0.695\n",
      "[74,   400] loss: 0.520\n",
      "[74,   500] loss: 0.620\n",
      "[74,   600] loss: 0.571\n",
      "[74,   700] loss: 0.568\n",
      "[74,   800] loss: 0.577\n",
      "[74,   900] loss: 0.637\n",
      "[74,  1000] loss: 0.634\n",
      "[74,  1100] loss: 0.626\n",
      "[74,  1200] loss: 0.696\n",
      "[74,  1300] loss: 0.677\n",
      "[74,  1400] loss: 0.566\n",
      "[74,  1500] loss: 0.619\n",
      "[74,  1600] loss: 0.542\n",
      "[74,  1700] loss: 0.510\n",
      "[74,  1800] loss: 0.637\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "[75,   100] loss: 0.635\n",
      "[75,   200] loss: 0.656\n",
      "[75,   300] loss: 0.606\n",
      "[75,   400] loss: 0.506\n",
      "[75,   500] loss: 0.593\n",
      "[75,   600] loss: 0.520\n",
      "[75,   700] loss: 0.581\n",
      "[75,   800] loss: 0.576\n",
      "[75,   900] loss: 0.589\n",
      "[75,  1000] loss: 0.707\n",
      "[75,  1100] loss: 0.606\n",
      "[75,  1200] loss: 0.601\n",
      "[75,  1300] loss: 0.552\n",
      "[75,  1400] loss: 0.596\n",
      "[75,  1500] loss: 0.608\n",
      "[75,  1600] loss: 0.646\n",
      "[75,  1700] loss: 0.533\n",
      "[75,  1800] loss: 0.573\n",
      "[76,   100] loss: 0.650\n",
      "[76,   200] loss: 0.586\n",
      "[76,   300] loss: 0.571\n",
      "[76,   400] loss: 0.551\n",
      "[76,   500] loss: 0.697\n",
      "[76,   600] loss: 0.640\n",
      "[76,   700] loss: 0.628\n",
      "[76,   800] loss: 0.608\n",
      "[76,   900] loss: 0.601\n",
      "[76,  1000] loss: 0.606\n",
      "[76,  1100] loss: 0.652\n",
      "[76,  1200] loss: 0.602\n",
      "[76,  1300] loss: 0.634\n",
      "[76,  1400] loss: 0.597\n",
      "[76,  1500] loss: 0.612\n",
      "[76,  1600] loss: 0.671\n",
      "[77,   100] loss: 0.510\n",
      "[77,   200] loss: 0.528\n",
      "[77,   300] loss: 0.514\n",
      "[77,   400] loss: 0.543\n",
      "[77,   500] loss: 0.520\n",
      "[77,   600] loss: 0.477\n",
      "[77,   700] loss: 0.555\n",
      "[77,   800] loss: 0.624\n",
      "[77,   900] loss: 0.589\n",
      "[77,  1000] loss: 0.563\n",
      "[77,  1100] loss: 0.475\n",
      "[77,  1200] loss: 0.573\n",
      "[77,  1300] loss: 0.487\n",
      "[77,  1400] loss: 0.674\n",
      "[77,  1500] loss: 0.579\n",
      "[77,  1600] loss: 0.659\n",
      "[77,  1700] loss: 0.565\n",
      "[78,   100] loss: 0.489\n",
      "[78,   200] loss: 0.648\n",
      "[78,   300] loss: 0.492\n",
      "[78,   400] loss: 0.609\n",
      "[78,   500] loss: 0.552\n",
      "[78,   600] loss: 0.567\n",
      "[78,   700] loss: 0.651\n",
      "[78,   800] loss: 0.583\n",
      "[78,   900] loss: 0.568\n",
      "[78,  1000] loss: 0.503\n",
      "[78,  1100] loss: 0.579\n",
      "[78,  1200] loss: 0.587\n",
      "[78,  1300] loss: 0.574\n",
      "[78,  1400] loss: 0.628\n",
      "[78,  1500] loss: 0.565\n",
      "[78,  1600] loss: 0.596\n",
      "[79,   100] loss: 0.651\n",
      "[79,   200] loss: 0.623\n",
      "[79,   300] loss: 0.608\n",
      "[79,   400] loss: 0.626\n",
      "[79,   500] loss: 0.628\n",
      "[79,   600] loss: 0.510\n",
      "[79,   700] loss: 0.621\n",
      "[79,   800] loss: 0.557\n",
      "[79,   900] loss: 0.609\n",
      "[79,  1000] loss: 0.664\n",
      "[79,  1100] loss: 0.609\n",
      "[79,  1200] loss: 0.623\n",
      "[79,  1300] loss: 0.656\n",
      "[79,  1400] loss: 0.609\n",
      "[79,  1500] loss: 0.666\n",
      "[79,  1600] loss: 0.588\n",
      "[79,  1700] loss: 0.666\n",
      "[79,  1800] loss: 0.585\n",
      "[79,  1900] loss: 0.678\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "[80,   100] loss: 0.515\n",
      "[80,   200] loss: 0.646\n",
      "[80,   300] loss: 0.566\n",
      "[80,   400] loss: 0.592\n",
      "[80,   500] loss: 0.524\n",
      "[80,   600] loss: 0.561\n",
      "[80,   700] loss: 0.646\n",
      "[80,   800] loss: 0.566\n",
      "[80,   900] loss: 0.488\n",
      "[80,  1000] loss: 0.527\n",
      "[80,  1100] loss: 0.583\n",
      "[80,  1200] loss: 0.476\n",
      "[80,  1300] loss: 0.541\n",
      "[80,  1400] loss: 0.569\n",
      "[80,  1500] loss: 0.578\n",
      "[80,  1600] loss: 0.602\n",
      "[80,  1700] loss: 0.554\n",
      "[80,  1800] loss: 0.648\n",
      "[81,   100] loss: 0.590\n",
      "[81,   200] loss: 0.619\n",
      "[81,   300] loss: 0.648\n",
      "[81,   400] loss: 0.674\n",
      "[81,   500] loss: 0.588\n",
      "[81,   600] loss: 0.579\n",
      "[81,   700] loss: 0.573\n",
      "[81,   800] loss: 0.560\n",
      "[81,   900] loss: 0.611\n",
      "[81,  1000] loss: 0.516\n",
      "[81,  1100] loss: 0.638\n",
      "[81,  1200] loss: 0.603\n",
      "[81,  1300] loss: 0.626\n",
      "[81,  1400] loss: 0.648\n",
      "[81,  1500] loss: 0.562\n",
      "[81,  1600] loss: 0.608\n",
      "[81,  1700] loss: 0.584\n",
      "[82,   100] loss: 0.650\n",
      "[82,   200] loss: 0.657\n",
      "[82,   300] loss: 0.603\n",
      "[82,   400] loss: 0.701\n",
      "[82,   500] loss: 0.598\n",
      "[82,   600] loss: 0.584\n",
      "[82,   700] loss: 0.543\n",
      "[82,   800] loss: 0.631\n",
      "[82,   900] loss: 0.600\n",
      "[82,  1000] loss: 0.680\n",
      "[82,  1100] loss: 0.685\n",
      "[82,  1200] loss: 0.670\n",
      "[82,  1300] loss: 0.614\n",
      "[82,  1400] loss: 0.673\n",
      "Error: Unexpected result string*\n",
      "[83,   100] loss: 0.625\n",
      "[83,   200] loss: 0.606\n",
      "[83,   300] loss: 0.603\n",
      "[83,   400] loss: 0.670\n",
      "[83,   500] loss: 0.692\n",
      "[83,   600] loss: 0.669\n",
      "[83,   700] loss: 0.624\n",
      "[83,   800] loss: 0.575\n",
      "[83,   900] loss: 0.665\n",
      "[83,  1000] loss: 0.714\n",
      "[83,  1100] loss: 0.522\n",
      "[83,  1200] loss: 0.568\n",
      "[83,  1300] loss: 0.632\n",
      "[83,  1400] loss: 0.642\n",
      "[83,  1500] loss: 0.694\n",
      "Error: Unexpected result string*\n",
      "[84,   100] loss: 0.542\n",
      "[84,   200] loss: 0.718\n",
      "[84,   300] loss: 0.556\n",
      "[84,   400] loss: 0.490\n",
      "[84,   500] loss: 0.514\n",
      "[84,   600] loss: 0.545\n",
      "[84,   700] loss: 0.681\n",
      "[84,   800] loss: 0.610\n",
      "[84,   900] loss: 0.560\n",
      "[84,  1000] loss: 0.586\n",
      "[84,  1100] loss: 0.469\n",
      "[84,  1200] loss: 0.623\n",
      "[84,  1300] loss: 0.508\n",
      "[84,  1400] loss: 0.629\n",
      "[84,  1500] loss: 0.523\n",
      "[84,  1600] loss: 0.507\n",
      "[84,  1700] loss: 0.477\n",
      "[84,  1800] loss: 0.656\n",
      "[85,   100] loss: 0.578\n",
      "[85,   200] loss: 0.578\n",
      "[85,   300] loss: 0.597\n",
      "[85,   400] loss: 0.584\n",
      "[85,   500] loss: 0.636\n",
      "[85,   600] loss: 0.533\n",
      "[85,   700] loss: 0.667\n",
      "[85,   800] loss: 0.622\n",
      "[85,   900] loss: 0.721\n",
      "[85,  1000] loss: 0.660\n",
      "[85,  1100] loss: 0.667\n",
      "[85,  1200] loss: 0.554\n",
      "[85,  1300] loss: 0.555\n",
      "[85,  1400] loss: 0.571\n",
      "[85,  1500] loss: 0.564\n",
      "[85,  1600] loss: 0.601\n",
      "[85,  1700] loss: 0.609\n",
      "[85,  1800] loss: 0.648\n",
      "[86,   100] loss: 0.602\n",
      "[86,   200] loss: 0.511\n",
      "[86,   300] loss: 0.538\n",
      "[86,   400] loss: 0.581\n",
      "[86,   500] loss: 0.709\n",
      "[86,   600] loss: 0.717\n",
      "[86,   700] loss: 0.607\n",
      "[86,   800] loss: 0.711\n",
      "[86,   900] loss: 0.586\n",
      "[86,  1000] loss: 0.641\n",
      "[86,  1100] loss: 0.596\n",
      "[86,  1200] loss: 0.644\n",
      "[86,  1300] loss: 0.597\n",
      "[86,  1400] loss: 0.711\n",
      "[86,  1500] loss: 0.585\n",
      "Error: Unexpected result string*\n",
      "[87,   100] loss: 0.598\n",
      "[87,   200] loss: 0.589\n",
      "[87,   300] loss: 0.610\n",
      "[87,   400] loss: 0.659\n",
      "[87,   500] loss: 0.611\n",
      "[87,   600] loss: 0.603\n",
      "[87,   700] loss: 0.532\n",
      "[87,   800] loss: 0.673\n",
      "[87,   900] loss: 0.624\n",
      "[87,  1000] loss: 0.600\n",
      "[87,  1100] loss: 0.577\n",
      "[87,  1200] loss: 0.581\n",
      "[87,  1300] loss: 0.633\n",
      "[87,  1400] loss: 0.655\n",
      "[87,  1500] loss: 0.629\n",
      "[87,  1600] loss: 0.568\n",
      "[87,  1700] loss: 0.550\n",
      "[88,   100] loss: 0.678\n",
      "[88,   200] loss: 0.591\n",
      "[88,   300] loss: 0.516\n",
      "[88,   400] loss: 0.577\n",
      "[88,   500] loss: 0.581\n",
      "[88,   600] loss: 0.553\n",
      "[88,   700] loss: 0.620\n",
      "[88,   800] loss: 0.526\n",
      "[88,   900] loss: 0.582\n",
      "[88,  1000] loss: 0.701\n",
      "[88,  1100] loss: 0.657\n",
      "[88,  1200] loss: 0.633\n",
      "[88,  1300] loss: 0.621\n",
      "[88,  1400] loss: 0.562\n",
      "[88,  1500] loss: 0.540\n",
      "[88,  1600] loss: 0.541\n",
      "[88,  1700] loss: 0.608\n",
      "[88,  1800] loss: 0.497\n",
      "[88,  1900] loss: 0.634\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "[89,   100] loss: 0.515\n",
      "[89,   200] loss: 0.457\n",
      "[89,   300] loss: 0.565\n",
      "[89,   400] loss: 0.596\n",
      "[89,   500] loss: 0.547\n",
      "[89,   600] loss: 0.545\n",
      "[89,   700] loss: 0.502\n",
      "[89,   800] loss: 0.580\n",
      "[89,   900] loss: 0.435\n",
      "[89,  1000] loss: 0.596\n",
      "[89,  1100] loss: 0.528\n",
      "[89,  1200] loss: 0.494\n",
      "[89,  1300] loss: 0.548\n",
      "[89,  1400] loss: 0.513\n",
      "[89,  1500] loss: 0.499\n",
      "[89,  1600] loss: 0.586\n",
      "[89,  1700] loss: 0.665\n",
      "[89,  1800] loss: 0.492\n",
      "[90,   100] loss: 0.586\n",
      "[90,   200] loss: 0.536\n",
      "[90,   300] loss: 0.629\n",
      "[90,   400] loss: 0.552\n",
      "[90,   500] loss: 0.668\n",
      "[90,   600] loss: 0.748\n",
      "[90,   700] loss: 0.764\n",
      "[90,   800] loss: 0.674\n",
      "[90,   900] loss: 0.656\n",
      "[90,  1000] loss: 0.604\n",
      "[90,  1100] loss: 0.678\n",
      "[90,  1200] loss: 0.548\n",
      "[90,  1300] loss: 0.607\n",
      "[90,  1400] loss: 0.724\n",
      "[90,  1500] loss: 0.626\n",
      "[90,  1600] loss: 0.707\n",
      "Error: Unexpected result string*\n",
      "[91,   100] loss: 0.574\n",
      "[91,   200] loss: 0.660\n",
      "[91,   300] loss: 0.591\n",
      "[91,   400] loss: 0.689\n",
      "[91,   500] loss: 0.611\n",
      "[91,   600] loss: 0.628\n",
      "[91,   700] loss: 0.627\n",
      "[91,   800] loss: 0.496\n",
      "[91,   900] loss: 0.609\n",
      "[91,  1000] loss: 0.571\n",
      "[91,  1100] loss: 0.620\n",
      "[91,  1200] loss: 0.653\n",
      "[91,  1300] loss: 0.637\n",
      "[91,  1400] loss: 0.663\n",
      "[91,  1500] loss: 0.568\n",
      "[91,  1600] loss: 0.725\n",
      "[91,  1700] loss: 0.735\n",
      "[91,  1800] loss: 0.678\n",
      "[92,   100] loss: 0.503\n",
      "[92,   200] loss: 0.552\n",
      "[92,   300] loss: 0.616\n",
      "[92,   400] loss: 0.529\n",
      "[92,   500] loss: 0.562\n",
      "[92,   600] loss: 0.528\n",
      "[92,   700] loss: 0.504\n",
      "[92,   800] loss: 0.567\n",
      "[92,   900] loss: 0.581\n",
      "[92,  1000] loss: 0.468\n",
      "[92,  1100] loss: 0.564\n",
      "[92,  1200] loss: 0.487\n",
      "[92,  1300] loss: 0.593\n",
      "[92,  1400] loss: 0.479\n",
      "[92,  1500] loss: 0.508\n",
      "[92,  1600] loss: 0.495\n",
      "[92,  1700] loss: 0.545\n",
      "[92,  1800] loss: 0.476\n",
      "[92,  1900] loss: 0.434\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "[93,   100] loss: 0.610\n",
      "[93,   200] loss: 0.540\n",
      "[93,   300] loss: 0.519\n",
      "[93,   400] loss: 0.599\n",
      "[93,   500] loss: 0.477\n",
      "[93,   600] loss: 0.472\n",
      "[93,   700] loss: 0.576\n",
      "[93,   800] loss: 0.570\n",
      "[93,   900] loss: 0.644\n",
      "[93,  1000] loss: 0.540\n",
      "[93,  1100] loss: 0.456\n",
      "[93,  1200] loss: 0.513\n",
      "[93,  1300] loss: 0.599\n",
      "[93,  1400] loss: 0.507\n",
      "[93,  1500] loss: 0.532\n",
      "[93,  1600] loss: 0.514\n",
      "[93,  1700] loss: 0.581\n",
      "[94,   100] loss: 0.599\n",
      "[94,   200] loss: 0.615\n",
      "[94,   300] loss: 0.637\n",
      "[94,   400] loss: 0.567\n",
      "[94,   500] loss: 0.696\n",
      "[94,   600] loss: 0.701\n",
      "[94,   700] loss: 0.577\n",
      "[94,   800] loss: 0.580\n",
      "[94,   900] loss: 0.649\n",
      "[94,  1000] loss: 0.609\n",
      "[94,  1100] loss: 0.635\n",
      "[94,  1200] loss: 0.564\n",
      "[94,  1300] loss: 0.614\n",
      "[94,  1400] loss: 0.652\n",
      "[94,  1500] loss: 0.574\n",
      "[94,  1600] loss: 0.602\n",
      "[94,  1700] loss: 0.731\n",
      "[94,  1800] loss: 0.710\n",
      "[94,  1900] loss: 0.613\n",
      "[95,   100] loss: 0.593\n",
      "[95,   200] loss: 0.679\n",
      "[95,   300] loss: 0.479\n",
      "[95,   400] loss: 0.563\n",
      "[95,   500] loss: 0.712\n",
      "[95,   600] loss: 0.579\n",
      "[95,   700] loss: 0.614\n",
      "[95,   800] loss: 0.536\n",
      "[95,   900] loss: 0.620\n",
      "[95,  1000] loss: 0.665\n",
      "[95,  1100] loss: 0.727\n",
      "[95,  1200] loss: 0.613\n",
      "[95,  1300] loss: 0.521\n",
      "[95,  1400] loss: 0.544\n",
      "[95,  1500] loss: 0.597\n",
      "[95,  1600] loss: 0.607\n",
      "[95,  1700] loss: 0.693\n",
      "[96,   100] loss: 0.555\n",
      "[96,   200] loss: 0.471\n",
      "[96,   300] loss: 0.522\n",
      "[96,   400] loss: 0.534\n",
      "[96,   500] loss: 0.480\n",
      "[96,   600] loss: 0.600\n",
      "[96,   700] loss: 0.619\n",
      "[96,   800] loss: 0.531\n",
      "[96,   900] loss: 0.578\n",
      "[96,  1000] loss: 0.646\n",
      "[96,  1100] loss: 0.671\n",
      "[96,  1200] loss: 0.643\n",
      "[96,  1300] loss: 0.674\n",
      "[96,  1400] loss: 0.535\n",
      "[96,  1500] loss: 0.593\n",
      "[96,  1600] loss: 0.634\n",
      "[96,  1700] loss: 0.609\n",
      "[96,  1800] loss: 0.550\n",
      "[97,   100] loss: 0.602\n",
      "[97,   200] loss: 0.618\n",
      "[97,   300] loss: 0.618\n",
      "[97,   400] loss: 0.578\n",
      "[97,   500] loss: 0.502\n",
      "[97,   600] loss: 0.612\n",
      "[97,   700] loss: 0.455\n",
      "[97,   800] loss: 0.617\n",
      "[97,   900] loss: 0.548\n",
      "[97,  1000] loss: 0.639\n",
      "[97,  1100] loss: 0.546\n",
      "[97,  1200] loss: 0.578\n",
      "[97,  1300] loss: 0.596\n",
      "[97,  1400] loss: 0.465\n",
      "[97,  1500] loss: 0.604\n",
      "[97,  1600] loss: 0.577\n",
      "[97,  1700] loss: 0.521\n",
      "[98,   100] loss: 0.567\n",
      "[98,   200] loss: 0.593\n",
      "[98,   300] loss: 0.576\n",
      "[98,   400] loss: 0.634\n",
      "[98,   500] loss: 0.534\n",
      "[98,   600] loss: 0.535\n",
      "[98,   700] loss: 0.588\n",
      "[98,   800] loss: 0.577\n",
      "[98,   900] loss: 0.618\n",
      "[98,  1000] loss: 0.633\n",
      "[98,  1100] loss: 0.538\n",
      "[98,  1200] loss: 0.557\n",
      "[98,  1300] loss: 0.496\n",
      "[98,  1400] loss: 0.489\n",
      "[98,  1500] loss: 0.534\n",
      "[98,  1600] loss: 0.642\n",
      "[98,  1700] loss: 0.579\n",
      "[98,  1800] loss: 0.639\n",
      "[98,  1900] loss: 0.594\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "[99,   100] loss: 0.633\n",
      "[99,   200] loss: 0.506\n",
      "[99,   300] loss: 0.670\n",
      "[99,   400] loss: 0.594\n",
      "[99,   500] loss: 0.766\n",
      "[99,   600] loss: 0.556\n",
      "[99,   700] loss: 0.674\n",
      "[99,   800] loss: 0.539\n",
      "[99,   900] loss: 0.637\n",
      "[99,  1000] loss: 0.753\n",
      "[99,  1100] loss: 0.646\n",
      "[99,  1200] loss: 0.690\n",
      "[99,  1300] loss: 0.670\n",
      "[99,  1400] loss: 0.684\n",
      "[99,  1500] loss: 0.652\n",
      "[99,  1600] loss: 0.695\n",
      "[99,  1700] loss: 0.631\n",
      "Error: Unexpected result string*\n",
      "[100,   100] loss: 0.683\n",
      "[100,   200] loss: 0.561\n",
      "[100,   300] loss: 0.712\n",
      "[100,   400] loss: 0.685\n",
      "[100,   500] loss: 0.461\n",
      "[100,   600] loss: 0.622\n",
      "[100,   700] loss: 0.665\n",
      "[100,   800] loss: 0.631\n",
      "[100,   900] loss: 0.608\n",
      "[100,  1000] loss: 0.564\n",
      "[100,  1100] loss: 0.688\n",
      "[100,  1200] loss: 0.585\n",
      "[100,  1300] loss: 0.450\n",
      "[100,  1400] loss: 0.662\n",
      "[100,  1500] loss: 0.636\n",
      "[100,  1600] loss: 0.537\n",
      "[100,  1700] loss: 0.578\n",
      "[100,  1800] loss: 0.537\n",
      "[101,   100] loss: 0.621\n",
      "[101,   200] loss: 0.572\n",
      "[101,   300] loss: 0.547\n",
      "[101,   400] loss: 0.683\n",
      "[101,   500] loss: 0.627\n",
      "[101,   600] loss: 0.581\n",
      "[101,   700] loss: 0.657\n",
      "[101,   800] loss: 0.576\n",
      "[101,   900] loss: 0.606\n",
      "[101,  1000] loss: 0.571\n",
      "[101,  1100] loss: 0.647\n",
      "[101,  1200] loss: 0.573\n",
      "[101,  1300] loss: 0.626\n",
      "[101,  1400] loss: 0.579\n",
      "[101,  1500] loss: 0.662\n",
      "[101,  1600] loss: 0.638\n",
      "[101,  1700] loss: 0.523\n",
      "Error: Unexpected result string*\n",
      "[102,   100] loss: 0.700\n",
      "[102,   200] loss: 0.670\n",
      "[102,   300] loss: 0.644\n",
      "[102,   400] loss: 0.650\n",
      "[102,   500] loss: 0.590\n",
      "[102,   600] loss: 0.633\n",
      "[102,   700] loss: 0.657\n",
      "[102,   800] loss: 0.715\n",
      "[102,   900] loss: 0.610\n",
      "[102,  1000] loss: 0.625\n",
      "[102,  1100] loss: 0.536\n",
      "[102,  1200] loss: 0.602\n",
      "[102,  1300] loss: 0.718\n",
      "[102,  1400] loss: 0.631\n",
      "[102,  1500] loss: 0.625\n",
      "[102,  1600] loss: 0.592\n",
      "[102,  1700] loss: 0.621\n",
      "[102,  1800] loss: 0.630\n",
      "[102,  1900] loss: 0.692\n",
      "[103,   100] loss: 0.586\n",
      "[103,   200] loss: 0.552\n",
      "[103,   300] loss: 0.549\n",
      "[103,   400] loss: 0.667\n",
      "[103,   500] loss: 0.594\n",
      "[103,   600] loss: 0.603\n",
      "[103,   700] loss: 0.609\n",
      "[103,   800] loss: 0.659\n",
      "[103,   900] loss: 0.577\n",
      "[103,  1000] loss: 0.577\n",
      "[103,  1100] loss: 0.658\n",
      "[103,  1200] loss: 0.660\n",
      "[103,  1300] loss: 0.629\n",
      "[103,  1400] loss: 0.598\n",
      "[103,  1500] loss: 0.594\n",
      "[103,  1600] loss: 0.586\n",
      "[103,  1700] loss: 0.677\n",
      "[103,  1800] loss: 0.542\n",
      "[103,  1900] loss: 0.592\n",
      "[104,   100] loss: 0.533\n",
      "[104,   200] loss: 0.643\n",
      "[104,   300] loss: 0.665\n",
      "[104,   400] loss: 0.688\n",
      "[104,   500] loss: 0.689\n",
      "[104,   600] loss: 0.606\n",
      "[104,   700] loss: 0.661\n",
      "[104,   800] loss: 0.634\n",
      "[104,   900] loss: 0.567\n",
      "[104,  1000] loss: 0.604\n",
      "[104,  1100] loss: 0.579\n",
      "[104,  1200] loss: 0.592\n",
      "[104,  1300] loss: 0.579\n",
      "[104,  1400] loss: 0.554\n",
      "[104,  1500] loss: 0.653\n",
      "[104,  1600] loss: 0.610\n",
      "[104,  1700] loss: 0.589\n",
      "[104,  1800] loss: 0.570\n",
      "[105,   100] loss: 0.549\n",
      "[105,   200] loss: 0.584\n",
      "[105,   300] loss: 0.566\n",
      "[105,   400] loss: 0.631\n",
      "[105,   500] loss: 0.521\n",
      "[105,   600] loss: 0.598\n",
      "[105,   700] loss: 0.520\n",
      "[105,   800] loss: 0.623\n",
      "[105,   900] loss: 0.481\n",
      "[105,  1000] loss: 0.602\n",
      "[105,  1100] loss: 0.549\n",
      "[105,  1200] loss: 0.664\n",
      "[105,  1300] loss: 0.476\n",
      "[105,  1400] loss: 0.535\n",
      "[105,  1500] loss: 0.591\n",
      "[105,  1600] loss: 0.644\n",
      "[105,  1700] loss: 0.587\n",
      "[105,  1800] loss: 0.613\n",
      "[106,   100] loss: 0.462\n",
      "[106,   200] loss: 0.559\n",
      "[106,   300] loss: 0.629\n",
      "[106,   400] loss: 0.525\n",
      "[106,   500] loss: 0.564\n",
      "[106,   600] loss: 0.516\n",
      "[106,   700] loss: 0.524\n",
      "[106,   800] loss: 0.500\n",
      "[106,   900] loss: 0.563\n",
      "[106,  1000] loss: 0.668\n",
      "[106,  1100] loss: 0.524\n",
      "[106,  1200] loss: 0.582\n",
      "[106,  1300] loss: 0.621\n",
      "[106,  1400] loss: 0.527\n",
      "[106,  1500] loss: 0.518\n",
      "[106,  1600] loss: 0.511\n",
      "[106,  1700] loss: 0.620\n",
      "[106,  1800] loss: 0.537\n",
      "[106,  1900] loss: 0.626\n",
      "[107,   100] loss: 0.582\n",
      "[107,   200] loss: 0.546\n",
      "[107,   300] loss: 0.611\n",
      "[107,   400] loss: 0.635\n",
      "[107,   500] loss: 0.585\n",
      "[107,   600] loss: 0.603\n",
      "[107,   700] loss: 0.653\n",
      "[107,   800] loss: 0.680\n",
      "[107,   900] loss: 0.604\n",
      "[107,  1000] loss: 0.623\n",
      "[107,  1100] loss: 0.611\n",
      "[107,  1200] loss: 0.607\n",
      "[107,  1300] loss: 0.753\n",
      "[107,  1400] loss: 0.596\n",
      "[107,  1500] loss: 0.584\n",
      "[107,  1600] loss: 0.621\n",
      "[107,  1700] loss: 0.642\n",
      "[107,  1800] loss: 0.678\n",
      "[108,   100] loss: 0.711\n",
      "[108,   200] loss: 0.627\n",
      "[108,   300] loss: 0.678\n",
      "[108,   400] loss: 0.627\n",
      "[108,   500] loss: 0.633\n",
      "[108,   600] loss: 0.671\n",
      "[108,   700] loss: 0.660\n",
      "[108,   800] loss: 0.680\n",
      "[108,   900] loss: 0.700\n",
      "[108,  1000] loss: 0.694\n",
      "[108,  1100] loss: 0.592\n",
      "[108,  1200] loss: 0.577\n",
      "[108,  1300] loss: 0.564\n",
      "[108,  1400] loss: 0.610\n",
      "[108,  1500] loss: 0.582\n",
      "[108,  1600] loss: 0.667\n",
      "[108,  1700] loss: 0.701\n",
      "[108,  1800] loss: 0.612\n",
      "[108,  1900] loss: 0.713\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "Error: Unexpected result string*\n",
      "[109,   100] loss: 0.576\n",
      "[109,   200] loss: 0.477\n",
      "[109,   300] loss: 0.541\n",
      "[109,   400] loss: 0.530\n",
      "[109,   500] loss: 0.570\n",
      "[109,   600] loss: 0.574\n",
      "[109,   700] loss: 0.677\n",
      "[109,   800] loss: 0.635\n",
      "[109,   900] loss: 0.525\n",
      "[109,  1000] loss: 0.574\n",
      "[109,  1100] loss: 0.556\n",
      "[109,  1200] loss: 0.469\n",
      "[109,  1300] loss: 0.693\n",
      "[109,  1400] loss: 0.672\n",
      "[109,  1500] loss: 0.633\n",
      "[109,  1600] loss: 0.652\n",
      "[109,  1700] loss: 0.509\n",
      "[109,  1800] loss: 0.554\n",
      "Error: Unexpected result string*\n",
      "[110,   100] loss: 0.594\n",
      "[110,   200] loss: 0.588\n",
      "[110,   300] loss: 0.556\n",
      "[110,   400] loss: 0.685\n",
      "[110,   500] loss: 0.585\n",
      "[110,   600] loss: 0.610\n",
      "[110,   700] loss: 0.676\n",
      "[110,   800] loss: 0.568\n",
      "[110,   900] loss: 0.527\n",
      "[110,  1000] loss: 0.676\n",
      "[110,  1100] loss: 0.687\n",
      "[110,  1200] loss: 0.545\n",
      "[110,  1300] loss: 0.718\n",
      "[110,  1400] loss: 0.554\n",
      "[110,  1500] loss: 0.678\n",
      "[110,  1600] loss: 0.613\n",
      "[110,  1700] loss: 0.606\n",
      "[110,  1800] loss: 0.512\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m     11\u001b[0m     running_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(trainLoader\u001b[39m.\u001b[39;49mget_data()):\n\u001b[1;32m     13\u001b[0m         \u001b[39m# Get the inputs\u001b[39;00m\n\u001b[1;32m     14\u001b[0m         inputs, labels \u001b[39m=\u001b[39m data\n\u001b[1;32m     16\u001b[0m         inputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(inputs, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n",
      "Cell \u001b[0;32mIn[51], line 20\u001b[0m, in \u001b[0;36mDataLoader.get_data\u001b[0;34m(self, step)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_data\u001b[39m(\u001b[39mself\u001b[39m, step\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m):\n\u001b[0;32m---> 20\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_data(step)\n\u001b[1;32m     21\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m step\n\u001b[1;32m     23\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(X, y))\n",
      "Cell \u001b[0;32mIn[51], line 13\u001b[0m, in \u001b[0;36mDataLoader._create_data\u001b[0;34m(self, step)\u001b[0m\n\u001b[1;32m     10\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart\u001b[39m+\u001b[39mstep\u001b[39m}\u001b[39;00m\u001b[39my.npy\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     X, y \u001b[39m=\u001b[39m createData(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstart, step)\n\u001b[1;32m     14\u001b[0m     np\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart\u001b[39m+\u001b[39mstep\u001b[39m}\u001b[39;00m\u001b[39mX.npy\u001b[39m\u001b[39m\"\u001b[39m, X)\n\u001b[1;32m     15\u001b[0m     np\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart\u001b[39m+\u001b[39mstep\u001b[39m}\u001b[39;00m\u001b[39my.npy\u001b[39m\u001b[39m\"\u001b[39m, y)\n",
      "Cell \u001b[0;32mIn[48], line 55\u001b[0m, in \u001b[0;36mcreateData\u001b[0;34m(start, n_data)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDATABASE4U_CLEANED.pgn\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m rf:\n\u001b[1;32m     54\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start):\n\u001b[0;32m---> 55\u001b[0m         game \u001b[39m=\u001b[39m chess\u001b[39m.\u001b[39;49mpgn\u001b[39m.\u001b[39;49mread_game(rf)\n\u001b[1;32m     57\u001b[0m     X \u001b[39m=\u001b[39m []\n\u001b[1;32m     58\u001b[0m     y \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/chess/pgn.py:1690\u001b[0m, in \u001b[0;36mread_game\u001b[0;34m(handle, Visitor)\u001b[0m\n\u001b[1;32m   1688\u001b[0m     skip_variation_depth \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1689\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1690\u001b[0m     visitor\u001b[39m.\u001b[39;49mvisit_move(board_stack[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], move)\n\u001b[1;32m   1691\u001b[0m     board_stack[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mpush(move)\n\u001b[1;32m   1692\u001b[0m visitor\u001b[39m.\u001b[39mvisit_board(board_stack[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/chess/pgn.py:1169\u001b[0m, in \u001b[0;36mGameBuilder.visit_move\u001b[0;34m(self, board, move)\u001b[0m\n\u001b[1;32m   1166\u001b[0m         new_comment \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstarting_comment, comment]\n\u001b[1;32m   1167\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstarting_comment \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, new_comment))\n\u001b[0;32m-> 1169\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_move\u001b[39m(\u001b[39mself\u001b[39m, board: chess\u001b[39m.\u001b[39mBoard, move: chess\u001b[39m.\u001b[39mMove) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1170\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariation_stack[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariation_stack[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39madd_variation(move)\n\u001b[1;32m   1171\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariation_stack[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mstarting_comment \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstarting_comment\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = MyNetwork()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Train the network\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1} of {num_epochs}\")\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainLoader.get_data()):\n",
    "        # Get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # save model into an .h5 file every 10 epochs\n",
    "    if epoch % 10 == 9:\n",
    "        torch.save(net.state_dict(), f\"model_{epoch}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ar-yukoh.shimizu/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "trainLoader = DataLoader(0)\n",
    "a = trainLoader.get_data(10)\n",
    "\n",
    "for i, data in enumerate(a):\n",
    "    # Get the inputs\n",
    "    inputs, labels = data\n",
    "\n",
    "    # convert inputs and labels into torch tensors\n",
    "    inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "    labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    # Zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward + backward + optimize\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print statistics\n",
    "    running_loss += loss.item()\n",
    "    if i % 100 == 99:\n",
    "        print('[%d, %5d] loss: %.3f' %\n",
    "                (epoch + 1, i + 1, running_loss / 100))\n",
    "        running_loss = 0.0\n",
    "\n",
    "# save model into an .h5 file every 10 epochs\n",
    "if epoch % 10 == 9:\n",
    "    torch.save(net.state_dict(), f\"model_{epoch}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyNetwork()\n",
    "\n",
    "model.load_state_dict(torch.load(\"model_109.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sample02.pgn\", \"r\") as f:\n",
    "    game = chess.pgn.read_game(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = list(game.mainline_moves())\n",
    "board = game.board()\n",
    "\n",
    "for i in range(10):\n",
    "    board.push(lst[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" version=\"1.2\" baseProfile=\"tiny\" viewBox=\"0 0 390 390\" width=\"390\" height=\"390\"><desc><pre>. . . . . k . r\n. . p Q . p p p\n. . . . . . q .\n. . . R . . . .\n. . . . . b . .\n. . . . . . . P\nP P P . . P P .\n. . . . K . . R</pre></desc><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"white-rook\" class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\" /><path d=\"M34 14l-3 3H14l-3-3\" /><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\" /><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\" /></g><g id=\"white-queen\" class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\" /><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\" /></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g id=\"black-pawn\" class=\"black pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#000\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"black-bishop\" class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\" /><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\" /></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\" /></g><g id=\"black-queen\" class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\" /><circle cx=\"14\" cy=\"9\" r=\"2.75\" /><circle cx=\"22.5\" cy=\"8\" r=\"2.75\" /><circle cx=\"31\" cy=\"9\" r=\"2.75\" /><circle cx=\"39\" cy=\"12\" r=\"2.75\" /></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\" /><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\" /></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g></defs><rect x=\"0\" y=\"0\" width=\"390\" height=\"390\" fill=\"#212121\" /><g transform=\"translate(20, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(65, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(110, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(155, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(200, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(245, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(290, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(335, 0) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light lastmove e8\" stroke=\"none\" fill=\"#cdd16a\" /><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark lastmove f8\" stroke=\"none\" fill=\"#aaa23b\" /><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\" /><use href=\"#white-king\" xlink:href=\"#white-king\" transform=\"translate(195, 330)\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(330, 330)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(15, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(60, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(105, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(240, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(285, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(330, 240)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(240, 195)\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(150, 150)\" /><use href=\"#black-queen\" xlink:href=\"#black-queen\" transform=\"translate(285, 105)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(105, 60)\" /><use href=\"#white-queen\" xlink:href=\"#white-queen\" transform=\"translate(150, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(240, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(285, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(330, 60)\" /><use href=\"#black-king\" xlink:href=\"#black-king\" transform=\"translate(240, 15)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(330, 15)\" /></svg>",
      "text/plain": [
       "Board('5k1r/2pQ1ppp/6q1/3R4/5b2/7P/PPP2PP1/4K2R w K - 1 21')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(38, 40):\n",
    "    board.push(lst[i])\n",
    "\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1723])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(model(torch.tensor(createStateObj(board), dtype=torch.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<LegalMoveGenerator at 0x126f24970 (Qe8+, Qd8#, Qc8+, Qxf7+, Qe7+, Qxc7, Qe6, Qd6+, Qc6, Qf5, Qb5, Qg4, Qa4, Rd6, Rh5, Rg5, Rf5, Re5, Rc5, Rb5, Ra5, Rd4, Rd3, Rd2, Rd1, Rh2, Rg1, Rf1, Ke2, Kf1, Kd1, O-O, h4, g3, f3, c3, b3, a3, g4, c4, b4, a4)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board.legal_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Move.from_uci('d7e8'),\n",
       " Move.from_uci('d7d8'),\n",
       " Move.from_uci('d7c8'),\n",
       " Move.from_uci('d7f7'),\n",
       " Move.from_uci('d7e7'),\n",
       " Move.from_uci('d7c7'),\n",
       " Move.from_uci('d7e6'),\n",
       " Move.from_uci('d7d6'),\n",
       " Move.from_uci('d7c6'),\n",
       " Move.from_uci('d7f5'),\n",
       " Move.from_uci('d7b5'),\n",
       " Move.from_uci('d7g4'),\n",
       " Move.from_uci('d7a4'),\n",
       " Move.from_uci('d5d6'),\n",
       " Move.from_uci('d5h5'),\n",
       " Move.from_uci('d5g5'),\n",
       " Move.from_uci('d5f5'),\n",
       " Move.from_uci('d5e5'),\n",
       " Move.from_uci('d5c5'),\n",
       " Move.from_uci('d5b5'),\n",
       " Move.from_uci('d5a5'),\n",
       " Move.from_uci('d5d4'),\n",
       " Move.from_uci('d5d3'),\n",
       " Move.from_uci('d5d2'),\n",
       " Move.from_uci('d5d1'),\n",
       " Move.from_uci('h1h2'),\n",
       " Move.from_uci('h1g1'),\n",
       " Move.from_uci('h1f1'),\n",
       " Move.from_uci('e1e2'),\n",
       " Move.from_uci('e1f1'),\n",
       " Move.from_uci('e1d1'),\n",
       " Move.from_uci('e1g1'),\n",
       " Move.from_uci('h3h4'),\n",
       " Move.from_uci('g2g3'),\n",
       " Move.from_uci('f2f3'),\n",
       " Move.from_uci('c2c3'),\n",
       " Move.from_uci('b2b3'),\n",
       " Move.from_uci('a2a3'),\n",
       " Move.from_uci('g2g4'),\n",
       " Move.from_uci('c2c4'),\n",
       " Move.from_uci('b2b4'),\n",
       " Move.from_uci('a2a4')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(board.legal_moves)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
